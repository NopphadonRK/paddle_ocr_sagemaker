{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4031461c",
   "metadata": {},
   "source": [
    "# PaddleOCR Text Recognition Training on Amazon SageMaker\n",
    "\n",
    "This notebook demonstrates how to train **Text Recognition models only** using PaddleOCR on Amazon SageMaker with GPU support.\n",
    "\n",
    "## Key Features:\n",
    "- **‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Text Recognition** (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° Detection)\n",
    "- ‡πÉ‡∏ä‡πâ `tools/train_rec.py` script\n",
    "- ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö annotation: `image_path\\ttext_content`\n",
    "- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö CRNN, SVTR, PP-OCRv4 architectures\n",
    "- S3 integration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data ‡πÅ‡∏•‡∏∞ model management\n",
    "\n",
    "## Requirements:\n",
    "- Amazon SageMaker Notebook Instance ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö GPU\n",
    "- PaddlePaddle GPU version\n",
    "- ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á S3 bucket ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ce87b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & GPU Check\n",
    "\n",
    "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Text Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö SageMaker version\n",
    "print(f\"SageMaker version: {sagemaker.__version__}\")\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ SageMaker session ‡πÅ‡∏•‡∏∞ role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Default S3 bucket: {bucket}\")\n",
    "\n",
    "print(\"‚úÖ Basic environment setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PaddlePaddle GPU version\n",
    "print(\"üöÄ Installing PaddlePaddle GPU version...\")\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \n",
    "    \"paddlepaddle-gpu==2.5.2\", \"-f\", \n",
    "    \"https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\"\n",
    "], check=True)\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n",
    "print(\"üì¶ Installing additional dependencies...\")\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \n",
    "    \"opencv-python-headless\", \"imgaug\", \"pyclipper\", \"lmdb\", \"tqdm\", \n",
    "    \"numpy\", \"visualdl\", \"python-Levenshtein\", \"shapely\", \"pyclipper\",\n",
    "    \"easydict\", \"scikit-image\"\n",
    "], check=True)\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e129b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU availability\n",
    "import paddle\n",
    "\n",
    "print(f\"üîç PaddlePaddle version: {paddle.__version__}\")\n",
    "print(f\"üéÆ GPU available: {paddle.is_compiled_with_cuda()}\")\n",
    "\n",
    "if paddle.is_compiled_with_cuda():\n",
    "    print(f\"üî• GPU count: {paddle.device.cuda.device_count()}\")\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPU\n",
    "    for i in range(paddle.device.cuda.device_count()):\n",
    "        gpu_name = paddle.device.cuda.get_device_properties(i).name\n",
    "        gpu_memory = paddle.device.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "        print(f\"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"‚ùå GPU not available! Please use GPU-enabled instance.\")\n",
    "    \n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ GPU ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "assert paddle.is_compiled_with_cuda(), \"GPU is required for training!\"\n",
    "print(\"‚úÖ GPU check passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ee53f",
   "metadata": {},
   "source": [
    "## 2. Clone PaddleOCR Repository & Install Dependencies\n",
    "\n",
    "‡πÇ‡∏Ñ‡∏•‡∏ô Official PaddleOCR Repository ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bda073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddleOCR\n",
    "PADDLEOCR_DIR = \"/home/ec2-user/SageMaker/PaddleOCR\"\n",
    "WORK_DIR = \"/home/ec2-user/SageMaker/paddle_ocr_recognition\"\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á working directory\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "# ‡πÇ‡∏Ñ‡∏•‡∏ô PaddleOCR repository\n",
    "if not os.path.exists(PADDLEOCR_DIR):\n",
    "    print(\"üöÄ Cloning PaddleOCR repository...\")\n",
    "    subprocess.run([\n",
    "        \"git\", \"clone\", \"https://github.com/PaddlePaddle/PaddleOCR.git\", \n",
    "        PADDLEOCR_DIR\n",
    "    ], check=True)\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"üìÅ PaddleOCR repository already exists.\")\n",
    "\n",
    "# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ working directory\n",
    "os.chdir(PADDLEOCR_DIR)\n",
    "print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PaddleOCR requirements\n",
    "print(\"üì¶ Installing PaddleOCR requirements...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n",
    "\n",
    "print(\"‚úÖ PaddleOCR setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2227f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ S3 paths ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition data\n",
    "S3_BUCKET = bucket\n",
    "S3_RECOGNITION_DATA_PREFIX = \"paddleocr-recognition-data\"\n",
    "S3_RECOGNITION_MODEL_PREFIX = \"paddleocr-recognition-models\"\n",
    "\n",
    "# Local paths ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition\n",
    "LOCAL_RECOGNITION_DATA_DIR = os.path.join(WORK_DIR, \"recognition_data\")\n",
    "LOCAL_RECOGNITION_CONFIG_DIR = os.path.join(WORK_DIR, \"recognition_configs\")\n",
    "LOCAL_RECOGNITION_MODEL_DIR = os.path.join(WORK_DIR, \"recognition_models\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á directories\n",
    "for dir_path in [LOCAL_RECOGNITION_DATA_DIR, LOCAL_RECOGNITION_CONFIG_DIR, LOCAL_RECOGNITION_MODEL_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"üìÅ S3 Configuration:\")\n",
    "print(f\"   Bucket: {S3_BUCKET}\")\n",
    "print(f\"   Recognition Data Prefix: {S3_RECOGNITION_DATA_PREFIX}\")\n",
    "print(f\"   Recognition Model Prefix: {S3_RECOGNITION_MODEL_PREFIX}\")\n",
    "\n",
    "print(\"\\nüìÇ Local Paths:\")\n",
    "print(f\"   Recognition Data: {LOCAL_RECOGNITION_DATA_DIR}\")\n",
    "print(f\"   Recognition Config: {LOCAL_RECOGNITION_CONFIG_DIR}\")\n",
    "print(f\"   Recognition Models: {LOCAL_RECOGNITION_MODEL_DIR}\")\n",
    "\n",
    "print(\"‚úÖ Path configuration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782464d1",
   "metadata": {},
   "source": [
    "## 3. Prepare Recognition Annotation Files\n",
    "\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: `image_path\\ttext_content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158484c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recognition_annotation_file(annotation_path, num_samples=10):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå annotation ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition\n",
    "    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: image_path\\ttext_content\n",
    "    \"\"\"\n",
    "    sample_annotations = []\n",
    "    \n",
    "    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition\n",
    "    sample_texts = [\n",
    "        \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö\", \"PaddleOCR\", \"Text Recognition\", \"1234567890\",\n",
    "        \"Hello World\", \"‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö\", \"Ê∑±Â∫¶Â≠¶‰π†\", \"Machine Learning\",\n",
    "        \"Amazon SageMaker\", \"‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\"\n",
    "    ]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image_path = f\"recognition_images/word_{i:03d}.jpg\"\n",
    "        text_content = sample_texts[i % len(sample_texts)]\n",
    "        \n",
    "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Recognition: image_path\\ttext_content\n",
    "        line = f\"{image_path}\\t{text_content}\"\n",
    "        sample_annotations.append(line)\n",
    "    \n",
    "    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå\n",
    "    with open(annotation_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(sample_annotations))\n",
    "    \n",
    "    print(f\"‚úÖ Created recognition annotation file: {annotation_path}\")\n",
    "    return annotation_path\n",
    "\n",
    "def validate_recognition_annotation_format(annotation_file):\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition\n",
    "    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: image_path\\ttext_content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                # ‡πÅ‡∏¢‡∏Å‡∏î‡πâ‡∏ß‡∏¢ tab\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) != 2:\n",
    "                    print(f\"‚ùå Error at line {line_num}: Expected 2 parts separated by tab, got {len(parts)}\")\n",
    "                    print(f\"   Line content: {repr(line)}\")\n",
    "                    return False\n",
    "                \n",
    "                image_path, text_content = parts\n",
    "                \n",
    "                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "                if not text_content.strip():\n",
    "                    print(f\"‚ùå Error at line {line_num}: Empty text content\")\n",
    "                    return False\n",
    "                \n",
    "                if line_num <= 3:  # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å\n",
    "                    print(f\"   Line {line_num}: {image_path} -> {text_content}\")\n",
    "        \n",
    "        print(\"‚úÖ Recognition annotation format validation passed!\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error validating annotation file: {e}\")\n",
    "        return False\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå annotation ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "train_annotation_file = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"train_recognition.txt\")\n",
    "val_annotation_file = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"val_recognition.txt\")\n",
    "\n",
    "print(\"üìù Creating sample recognition annotation files...\")\n",
    "create_recognition_annotation_file(train_annotation_file, 20)\n",
    "create_recognition_annotation_file(val_annotation_file, 5)\n",
    "\n",
    "print(\"\\nüîç Validating annotation files...\")\n",
    "validate_recognition_annotation_format(train_annotation_file)\n",
    "validate_recognition_annotation_format(val_annotation_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e597f1",
   "metadata": {},
   "source": [
    "## 4. Upload Recognition Data and Annotation to S3\n",
    "\n",
    "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition (‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß + ‡πÑ‡∏ü‡∏•‡πå annotation) ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_recognition_data_to_s3(local_data_path, s3_bucket, s3_prefix):\n",
    "    \"\"\"\n",
    "    ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3 bucket\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    uploaded_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(local_data_path):\n",
    "        for file in files:\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_file_path, local_data_path)\n",
    "            s3_key = f\"{s3_prefix}/{relative_path}\"\n",
    "            \n",
    "            print(f\"üì§ Uploading: {relative_path} -> s3://{s3_bucket}/{s3_key}\")\n",
    "            s3_client.upload_file(local_file_path, s3_bucket, s3_key)\n",
    "            uploaded_files.append(s3_key)\n",
    "    \n",
    "    print(f\"‚úÖ Uploaded {len(uploaded_files)} files to S3\")\n",
    "    return uploaded_files\n",
    "\n",
    "def create_sample_recognition_images():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition (‡∏à‡∏≥‡∏•‡∏≠‡∏á cropped text images)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "    images_dir = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"recognition_images\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "    sample_texts = [\n",
    "        \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö\", \"PaddleOCR\", \"Text Recognition\", \"1234567890\",\n",
    "        \"Hello World\", \"‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö\", \"Ê∑±Â∫¶Â≠¶‰π†\", \"Machine Learning\",\n",
    "        \"Amazon SageMaker\", \"‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\"\n",
    "    ]\n",
    "    \n",
    "    for i, text in enumerate(sample_texts[:10]):  # ‡∏™‡∏£‡πâ‡∏≤‡∏á 10 ‡∏£‡∏π‡∏õ\n",
    "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "        img = Image.new('RGB', (200, 50), color='white')\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÉ‡∏ä‡πâ default font)\n",
    "        try:\n",
    "            draw.text((10, 15), text, fill='black')\n",
    "        except:\n",
    "            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏Ç‡πÅ‡∏ó‡∏ô\n",
    "            draw.text((10, 15), f\"Text{i:03d}\", fill='black')\n",
    "        \n",
    "        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "        image_path = os.path.join(images_dir, f\"word_{i:03d}.jpg\")\n",
    "        img.save(image_path)\n",
    "        \n",
    "    print(f\"‚úÖ Created {len(sample_texts)} sample recognition images in {images_dir}\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "print(\"üñºÔ∏è Creating sample recognition images...\")\n",
    "create_sample_recognition_images()\n",
    "\n",
    "# ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3\n",
    "print(f\"\\nüì§ Uploading recognition data to S3 bucket: {S3_BUCKET}\")\n",
    "uploaded_files = upload_recognition_data_to_s3(\n",
    "    LOCAL_RECOGNITION_DATA_DIR, \n",
    "    S3_BUCKET, \n",
    "    S3_RECOGNITION_DATA_PREFIX\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Uploaded files preview (first 10):\")\n",
    "for i, file in enumerate(uploaded_files[:10]):\n",
    "    print(f\"   {i+1}. s3://{S3_BUCKET}/{file}\")\n",
    "\n",
    "if len(uploaded_files) > 10:\n",
    "    print(f\"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(uploaded_files) - 10} ‡πÑ‡∏ü‡∏•‡πå\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bce9d3",
   "metadata": {},
   "source": [
    "## 5. Download Recognition Data from S3\n",
    "\n",
    "‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition ‡∏à‡∏≤‡∏Å S3 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_recognition_data_from_s3(s3_bucket, s3_prefix, local_data_path):\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition ‡∏à‡∏≤‡∏Å S3 bucket\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    downloaded_files = []\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á directory ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ\n",
    "    os.makedirs(local_data_path, exist_ok=True)\n",
    "    \n",
    "    # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å S3\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=s3_bucket, Prefix=s3_prefix)\n",
    "    \n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                s3_key = obj['Key']\n",
    "                # ‡∏•‡∏ö prefix ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ relative path\n",
    "                relative_path = s3_key[len(s3_prefix):].lstrip('/')\n",
    "                local_file_path = os.path.join(local_data_path, relative_path)\n",
    "                \n",
    "                # ‡∏™‡∏£‡πâ‡∏≤‡∏á directory ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "                os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "                \n",
    "                print(f\"üì• Downloading: s3://{s3_bucket}/{s3_key} -> {relative_path}\")\n",
    "                s3_client.download_file(s3_bucket, s3_key, local_file_path)\n",
    "                downloaded_files.append(local_file_path)\n",
    "    \n",
    "    print(f\"‚úÖ Downloaded {len(downloaded_files)} files from S3\")\n",
    "    return downloaded_files\n",
    "\n",
    "def list_s3_recognition_data(s3_bucket, s3_prefix):\n",
    "    \"\"\"\n",
    "    ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå Recognition ‡πÉ‡∏ô S3\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        response = s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix)\n",
    "        \n",
    "        if 'Contents' in response:\n",
    "            files = []\n",
    "            for obj in response['Contents']:\n",
    "                files.append({\n",
    "                    'key': obj['Key'],\n",
    "                    'size': obj['Size'],\n",
    "                    'modified': obj['LastModified']\n",
    "                })\n",
    "            \n",
    "            print(f\"üìã Recognition data in s3://{s3_bucket}/{s3_prefix}:\")\n",
    "            for file_info in sorted(files, key=lambda x: x['key'])[:10]:  # ‡πÅ‡∏™‡∏î‡∏á 10 ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å\n",
    "                size_mb = file_info['size'] / (1024 * 1024)\n",
    "                print(f\"   üìÑ {file_info['key']} ({size_mb:.2f} MB)\")\n",
    "                \n",
    "            if len(files) > 10:\n",
    "                print(f\"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(files) - 10} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "                \n",
    "            return files\n",
    "        else:\n",
    "            print(\"üì≠ No files found in S3 bucket with the specified prefix.\")\n",
    "            return []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing S3 files: {e}\")\n",
    "        return []\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô S3\n",
    "print(\"üìã Listing recognition data in S3:\")\n",
    "s3_files = list_s3_recognition_data(S3_BUCKET, S3_RECOGNITION_DATA_PREFIX)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á clean directory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö download\n",
    "download_dir = os.path.join(WORK_DIR, \"downloaded_recognition_data\")\n",
    "if os.path.exists(download_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(download_dir)\n",
    "\n",
    "print(f\"\\nüì• Downloading recognition data to: {download_dir}\")\n",
    "downloaded_files = download_recognition_data_from_s3(\n",
    "    S3_BUCKET, \n",
    "    S3_RECOGNITION_DATA_PREFIX, \n",
    "    download_dir\n",
    ")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î\n",
    "print(f\"\\nüìÅ Downloaded files structure:\")\n",
    "for root, dirs, files in os.walk(download_dir):\n",
    "    level = root.replace(download_dir, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}üìÇ {os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:5]:  # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 5 ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å‡∏ï‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\n",
    "        print(f\"{subindent}üìÑ {file}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"{subindent}... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(files) - 5} ‡πÑ‡∏ü‡∏•‡πå\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717879d",
   "metadata": {},
   "source": [
    "## 6. Validate Recognition Annotation Format\n",
    "\n",
    "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_recognition_validation(annotation_file, image_base_dir=None):\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô\n",
    "    \"\"\"\n",
    "    print(f\"üîç Validating recognition annotation file: {annotation_file}\")\n",
    "    \n",
    "    if not os.path.exists(annotation_file):\n",
    "        print(f\"‚ùå Annotation file not found: {annotation_file}\")\n",
    "        return False\n",
    "    \n",
    "    issues = []\n",
    "    valid_lines = 0\n",
    "    text_lengths = []\n",
    "    \n",
    "    with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö tab-separated\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) != 2:\n",
    "                    issues.append(f\"Line {line_num}: Expected 2 parts (image_path\\\\ttext), got {len(parts)}\")\n",
    "                    continue\n",
    "                \n",
    "                image_path, text_content = parts\n",
    "                \n",
    "                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö image path\n",
    "                if not image_path.strip():\n",
    "                    issues.append(f\"Line {line_num}: Empty image path\")\n",
    "                    continue\n",
    "                \n",
    "                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö text content\n",
    "                if not text_content.strip():\n",
    "                    issues.append(f\"Line {line_num}: Empty text content\")\n",
    "                    continue\n",
    "                \n",
    "                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏ base directory)\n",
    "                if image_base_dir:\n",
    "                    full_image_path = os.path.join(image_base_dir, image_path)\n",
    "                    if not os.path.exists(full_image_path):\n",
    "                        issues.append(f\"Line {line_num}: Image file not found: {image_path}\")\n",
    "                \n",
    "                # ‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥\n",
    "                text_lengths.append(len(text_content))\n",
    "                valid_lines += 1\n",
    "                \n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "                if valid_lines <= 5:\n",
    "                    print(f\"   ‚úì Line {line_num}: {image_path} -> '{text_content}'\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                issues.append(f\"Line {line_num}: Error processing line - {str(e)}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n",
    "    print(f\"\\nüìä Validation Summary:\")\n",
    "    print(f\"   Valid lines: {valid_lines}\")\n",
    "    print(f\"   Issues found: {len(issues)}\")\n",
    "    \n",
    "    if text_lengths:\n",
    "        import numpy as np\n",
    "        print(f\"   Text length stats:\")\n",
    "        print(f\"     Min: {min(text_lengths)} characters\")\n",
    "        print(f\"     Max: {max(text_lengths)} characters\")\n",
    "        print(f\"     Average: {np.mean(text_lengths):.1f} characters\")\n",
    "    \n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö\n",
    "    if issues:\n",
    "        print(f\"\\n‚ùå Issues found:\")\n",
    "        for issue in issues[:10]:  # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 10 ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏£‡∏Å\n",
    "            print(f\"   ‚Ä¢ {issue}\")\n",
    "        if len(issues) > 10:\n",
    "            print(f\"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(issues) - 10} ‡∏õ‡∏±‡∏ç‡∏´‡∏≤\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ All validation checks passed!\")\n",
    "        return True\n",
    "\n",
    "def convert_detection_to_recognition_format(detection_annotation_file, output_recognition_file):\n",
    "    \"\"\"\n",
    "    ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå annotation ‡∏à‡∏≤‡∏Å Detection format ‡πÄ‡∏õ‡πá‡∏ô Recognition format\n",
    "    ‡∏à‡∏≤‡∏Å: image_path\\t[{\"transcription\": \"text\", \"points\": [...]}]\n",
    "    ‡πÄ‡∏õ‡πá‡∏ô: image_path\\ttext\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Converting detection annotation to recognition format...\")\n",
    "    \n",
    "    recognition_lines = []\n",
    "    \n",
    "    with open(detection_annotation_file, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) != 2:\n",
    "                    continue\n",
    "                \n",
    "                image_path, annotation_json = parts\n",
    "                annotations = json.loads(annotation_json)\n",
    "                \n",
    "                # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "                texts = []\n",
    "                for ann in annotations:\n",
    "                    if 'transcription' in ann:\n",
    "                        texts.append(ann['transcription'])\n",
    "                \n",
    "                if texts:\n",
    "                    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á\n",
    "                    combined_text = ' '.join(texts)\n",
    "                    recognition_line = f\"{image_path}\\t{combined_text}\"\n",
    "                    recognition_lines.append(recognition_line)\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Invalid JSON at line {line_num}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing line {line_num}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    with open(output_recognition_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(recognition_lines))\n",
    "    \n",
    "    print(f\"‚úÖ Converted {len(recognition_lines)} lines to recognition format\")\n",
    "    print(f\"   Output file: {output_recognition_file}\")\n",
    "    \n",
    "    return output_recognition_file\n",
    "\n",
    "# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå annotation ‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤\n",
    "downloaded_annotation_files = []\n",
    "for root, dirs, files in os.walk(download_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            downloaded_annotation_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"üìã Found annotation files to validate:\")\n",
    "for i, file_path in enumerate(downloaded_annotation_files):\n",
    "    print(f\"   {i+1}. {os.path.relpath(file_path, download_dir)}\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå\n",
    "print(f\"\\nüîç Validating annotation files...\")\n",
    "for annotation_file in downloaded_annotation_files:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    \n",
    "    # ‡∏´‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n",
    "    annotation_dir = os.path.dirname(annotation_file)\n",
    "    possible_image_dirs = [\n",
    "        os.path.join(annotation_dir, 'images'),\n",
    "        os.path.join(annotation_dir, 'recognition_images'),\n",
    "        annotation_dir\n",
    "    ]\n",
    "    \n",
    "    image_base_dir = None\n",
    "    for img_dir in possible_image_dirs:\n",
    "        if os.path.exists(img_dir) and any(f.lower().endswith(('.jpg', '.jpeg', '.png')) \n",
    "                                          for f in os.listdir(img_dir)):\n",
    "            image_base_dir = img_dir\n",
    "            break\n",
    "    \n",
    "    # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n",
    "    is_valid = comprehensive_recognition_validation(annotation_file, image_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf83d40",
   "metadata": {},
   "source": [
    "## 7. Prepare Recognition Configuration File (.yml)\n",
    "\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå configuration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Text Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recognition_training_config(base_config_path, output_config_path, \n",
    "                                     train_annotation_file, eval_annotation_file,\n",
    "                                     save_model_dir, architecture_type='CRNN'):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå configuration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Recognition\n",
    "    \n",
    "    Args:\n",
    "        base_config_path: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á base config file\n",
    "        output_config_path: Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å config ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß\n",
    "        train_annotation_file: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training\n",
    "        eval_annotation_file: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö evaluation\n",
    "        save_model_dir: Directory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model checkpoints\n",
    "        architecture_type: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á architecture ('CRNN', 'SVTR', 'PP-OCRv4')\n",
    "    \"\"\"\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î base configuration\n",
    "    with open(base_config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"üìÑ Loaded base config from: {base_config_path}\")\n",
    "    print(f\"   Architecture type: {architecture_type}\")\n",
    "    \n",
    "    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Global settings\n",
    "    config['Global']['save_model_dir'] = save_model_dir\n",
    "    config['Global']['checkpoints'] = None  # Start from scratch\n",
    "    config['Global']['use_gpu'] = True\n",
    "    config['Global']['epoch_num'] = 100  # ‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epoch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo\n",
    "    config['Global']['log_smooth_window'] = 20\n",
    "    config['Global']['print_batch_step'] = 10\n",
    "    config['Global']['save_epoch_step'] = 20\n",
    "    config['Global']['eval_batch_step'] = [0, 500]\n",
    "    config['Global']['cal_metric_during_train'] = True\n",
    "    \n",
    "    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ character dictionary (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ)\n",
    "    config['Global']['character_dict_path'] = 'ppocr/utils/ppocr_keys_v1.txt'\n",
    "    config['Global']['character_type'] = 'ch'  # ch = Chinese/Thai, en = English\n",
    "    config['Global']['max_text_length'] = 25\n",
    "    \n",
    "    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Train dataset\n",
    "    config['Train']['dataset']['name'] = 'SimpleDataSet'\n",
    "    config['Train']['dataset']['data_dir'] = os.path.dirname(train_annotation_file)\n",
    "    config['Train']['dataset']['label_file_list'] = [train_annotation_file]\n",
    "    \n",
    "    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Eval dataset\n",
    "    config['Eval']['dataset']['name'] = 'SimpleDataSet'\n",
    "    config['Eval']['dataset']['data_dir'] = os.path.dirname(eval_annotation_file)\n",
    "    config['Eval']['dataset']['label_file_list'] = [eval_annotation_file]\n",
    "    \n",
    "    # ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á Optimizer\n",
    "    if 'Optimizer' in config:\n",
    "        config['Optimizer']['lr']['learning_rate'] = 0.001\n",
    "        if 'regularizer' in config['Optimizer']:\n",
    "            config['Optimizer']['regularizer']['factor'] = 5.0e-05\n",
    "    \n",
    "    # ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á batch size ‡∏ï‡∏≤‡∏° GPU memory\n",
    "    if 'Train' in config and 'loader' in config['Train']:\n",
    "        config['Train']['loader']['batch_size_per_card'] = 32  # ‡∏•‡∏î‡∏ñ‡πâ‡∏≤ GPU memory ‡πÑ‡∏°‡πà‡∏û‡∏≠\n",
    "        config['Train']['loader']['num_workers'] = 4\n",
    "    \n",
    "    if 'Eval' in config and 'loader' in config['Eval']:\n",
    "        config['Eval']['loader']['batch_size_per_card'] = 32\n",
    "        config['Eval']['loader']['num_workers'] = 2\n",
    "    \n",
    "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå config ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß\n",
    "    os.makedirs(os.path.dirname(output_config_path), exist_ok=True)\n",
    "    with open(output_config_path, 'w', encoding='utf-8') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n",
    "    \n",
    "    print(f\"‚úÖ Created recognition training config: {output_config_path}\")\n",
    "    \n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n",
    "    print(f\\\"\\\\nüìã Key Configuration Settings:\\\")\n",
    "    print(f\\\"   Model save dir: {config['Global']['save_model_dir']}\\\")\n",
    "    print(f\\\"   Epochs: {config['Global']['epoch_num']}\\\")\n",
    "    print(f\\\"   Learning rate: {config.get('Optimizer', {}).get('lr', {}).get('learning_rate', 'Not set')}\\\")\n",
    "    print(f\\\"   Train data: {train_annotation_file}\\\")\n",
    "    print(f\\\"   Eval data: {eval_annotation_file}\\\")\n",
    "    print(f\\\"   Character type: {config['Global']['character_type']}\\\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "def list_available_recognition_configs():\n",
    "    \\\"\\\"\\\"\n",
    "    ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ config files ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition\n",
    "    \\\"\\\"\\\"\n",
    "    rec_config_dir = os.path.join(PADDLEOCR_DIR, \\\"configs\\\", \\\"rec\\\")\n",
    "    \n",
    "    if not os.path.exists(rec_config_dir):\n",
    "        print(f\\\"‚ùå Recognition config directory not found: {rec_config_dir}\\\")\n",
    "        return []\n",
    "    \n",
    "    config_files = []\n",
    "    for root, dirs, files in os.walk(rec_config_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.yml'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(full_path, rec_config_dir)\n",
    "                config_files.append({\n",
    "                    'name': relative_path,\n",
    "                    'full_path': full_path,\n",
    "                    'architecture': 'Unknown'\n",
    "                })\n",
    "    \n",
    "    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏£‡∏∞‡∏ö‡∏∏ architecture type\n",
    "    for config in config_files:\n",
    "        name_lower = config['name'].lower()\n",
    "        if 'crnn' in name_lower or 'bilstm' in name_lower:\n",
    "            config['architecture'] = 'CRNN'\n",
    "        elif 'svtr' in name_lower:\n",
    "            config['architecture'] = 'SVTR'\n",
    "        elif 'ocrv4' in name_lower or 'pp-ocrv4' in name_lower:\n",
    "            config['architecture'] = 'PP-OCRv4'\n",
    "        elif 'rare' in name_lower:\n",
    "            config['architecture'] = 'RareText'\n",
    "        elif 'vitstr' in name_lower:\n",
    "            config['architecture'] = 'ViTSTR'\n",
    "    \n",
    "    return config_files\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ config ‡∏ó‡∏µ‡πà‡∏°‡∏µ\n",
    "print(\\\"üîç Available Recognition Configuration Files:\\\")\n",
    "available_configs = list_available_recognition_configs()\n",
    "\n",
    "if available_configs:\n",
    "    print(f\\\"\\\\nüìã Found {len(available_configs)} recognition configs:\\\")\n",
    "    for i, config in enumerate(available_configs[:10]):  # ‡πÅ‡∏™‡∏î‡∏á 10 ‡∏≠‡∏±‡∏ô‡πÅ‡∏£‡∏Å\n",
    "        print(f\\\"   {i+1}. {config['name']} ({config['architecture']})\\\")\n",
    "    \n",
    "    if len(available_configs) > 10:\n",
    "        print(f\\\"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(available_configs) - 10} configs\\\")\n",
    "    \n",
    "    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å config ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
    "    recommended_configs = [\n",
    "        ('rec_mv3_none_bilstm_ctc.yml', 'CRNN - Basic, fast training'),\n",
    "        ('rec_svtr_base.yml', 'SVTR - Better accuracy'),\n",
    "        ('PP-OCRv4/en_PP-OCRv4_rec.yml', 'PP-OCRv4 - Latest model')\n",
    "    ]\n",
    "    \n",
    "    print(f\\\"\\\\nüåü Recommended configs:\\\")\n",
    "    for config_name, description in recommended_configs:\n",
    "        found = next((c for c in available_configs if config_name in c['name']), None)\n",
    "        if found:\n",
    "            print(f\\\"   ‚úì {config_name} - {description}\\\")\n",
    "            print(f\\\"     Path: {found['full_path']}\\\")\n",
    "        else:\n",
    "            print(f\\\"   ‚ùå {config_name} - Not found\\\")\n",
    "            \n",
    "else:\n",
    "    print(\\\"‚ùå No recognition config files found!\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á recognition config file\n",
    "# ‡πÉ‡∏ä‡πâ CRNN config ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)\n",
    "base_config_name = \"rec_mv3_none_bilstm_ctc.yml\"\n",
    "base_config_path = os.path.join(PADDLEOCR_DIR, \"configs\", \"rec\", base_config_name)\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ config file ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "if not os.path.exists(base_config_path):\n",
    "    print(f\"‚ùå Base config not found: {base_config_path}\")\n",
    "    # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ config ‡∏≠‡∏∑‡πà‡∏ô\n",
    "    alternative_configs = [\n",
    "        \"configs/rec/rec_r34_vd_none_bilstm_ctc.yml\",\n",
    "        \"configs/rec/rec_mv3_none_none_ctc.yml\"\n",
    "    ]\n",
    "    \n",
    "    for alt_config in alternative_configs:\n",
    "        alt_path = os.path.join(PADDLEOCR_DIR, alt_config)\n",
    "        if os.path.exists(alt_path):\n",
    "            base_config_path = alt_path\n",
    "            print(f\"‚úÖ Using alternative config: {alt_path}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"‚ùå No suitable recognition config found!\")\n",
    "\n",
    "if os.path.exists(base_config_path):\n",
    "    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ paths ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training\n",
    "    train_annotation_path = os.path.join(download_dir, \"train_recognition.txt\")\n",
    "    eval_annotation_path = os.path.join(download_dir, \"val_recognition.txt\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå annotation ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà\n",
    "    if not os.path.exists(train_annotation_path):\n",
    "        print(f\"‚ùå Train annotation file not found: {train_annotation_path}\")\n",
    "        # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤\n",
    "        train_annotation_path = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"train_recognition.txt\")\n",
    "        eval_annotation_path = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"val_recognition.txt\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training\n",
    "    output_config_path = os.path.join(LOCAL_RECOGNITION_CONFIG_DIR, \"recognition_training_config.yml\")\n",
    "    \n",
    "    print(f\"üîß Creating recognition training configuration...\")\n",
    "    print(f\"   Base config: {base_config_path}\")\n",
    "    print(f\"   Output config: {output_config_path}\")\n",
    "    print(f\"   Train data: {train_annotation_path}\")\n",
    "    print(f\"   Eval data: {eval_annotation_path}\")\n",
    "    print(f\"   Model save dir: {LOCAL_RECOGNITION_MODEL_DIR}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á config\n",
    "    config = create_recognition_training_config(\n",
    "        base_config_path=base_config_path,\n",
    "        output_config_path=output_config_path,\n",
    "        train_annotation_file=train_annotation_path,\n",
    "        eval_annotation_file=eval_annotation_path,\n",
    "        save_model_dir=LOCAL_RECOGNITION_MODEL_DIR,\n",
    "        architecture_type='CRNN'\n",
    "    )\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á config ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß\n",
    "    print(f\"\\nüîç Validating created config file...\")\n",
    "    try:\n",
    "        with open(output_config_path, 'r', encoding='utf-8') as f:\n",
    "            test_config = yaml.safe_load(f)\n",
    "        \n",
    "        required_sections = ['Global', 'Architecture', 'Loss', 'Optimizer', 'Train', 'Eval']\n",
    "        missing_sections = [section for section in required_sections if section not in test_config]\n",
    "        \n",
    "        if missing_sections:\n",
    "            print(f\"‚ùå Missing config sections: {missing_sections}\")\n",
    "        else:\n",
    "            print(\"‚úÖ Config validation passed!\")\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á architecture details\n",
    "            if 'Architecture' in test_config:\n",
    "                arch = test_config['Architecture']\n",
    "                print(f\"\\\\nüèóÔ∏è Architecture Details:\")\n",
    "                print(f\"   Model type: {arch.get('model_type', 'Not specified')}\")\n",
    "                print(f\"   Algorithm: {arch.get('algorithm', 'Not specified')}\")\n",
    "                if 'Backbone' in arch:\n",
    "                    print(f\"   Backbone: {arch['Backbone'].get('name', 'Not specified')}\")\n",
    "                if 'Head' in arch:\n",
    "                    print(f\"   Head: {arch['Head'].get('name', 'Not specified')}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error validating config: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed without a valid base config file!\")\n",
    "    \n",
    "print(f\"\\\\n‚úÖ Recognition configuration setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9664daf",
   "metadata": {},
   "source": [
    "## 8. Start Text Recognition Training with tools/train_rec.py\n",
    "\n",
    "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Text Recognition ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ script `tools/train_rec.py` ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recognition_training(config_path, resume_from=None):\n",
    "    \"\"\"\n",
    "    ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Text Recognition ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ tools/train_rec.py\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå configuration\n",
    "        resume_from: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á checkpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö resume (optional)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á PaddleOCR directory\n",
    "    os.chdir(PADDLEOCR_DIR)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Recognition\n",
    "    train_script = os.path.join(PADDLEOCR_DIR, \"tools\", \"train.py\")  # ‡πÉ‡∏ä‡πâ tools/train.py ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ train_rec.py ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "    train_rec_script = os.path.join(PADDLEOCR_DIR, \"tools\", \"train_rec.py\")\n",
    "    if os.path.exists(train_rec_script):\n",
    "        train_script = train_rec_script\n",
    "        print(f\"üéØ Using specialized recognition training script: train_rec.py\")\n",
    "    else:\n",
    "        print(f\"üìù Using general training script: train.py\")\n",
    "    \n",
    "    cmd = [sys.executable, train_script, \"-c\", config_path]\n",
    "    \n",
    "    if resume_from:\n",
    "        cmd.extend([\"-o\", f\"Global.checkpoints={resume_from}\"])\n",
    "    \n",
    "    print(f\"üöÄ Starting Recognition Training...\")\n",
    "    print(f\"   Command: {' '.join(cmd)}\")\n",
    "    print(f\"   Config: {config_path}\")\n",
    "    print(f\"   Working directory: {os.getcwd()}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á log file\n",
    "    log_file = os.path.join(LOCAL_RECOGNITION_MODEL_DIR, \"training.log\")\n",
    "    \n",
    "    try:\n",
    "        # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏ö‡∏ö non-blocking ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π output ‡πÑ‡∏î‡πâ\n",
    "        print(f\"üìä Training output will be saved to: {log_file}\")\n",
    "        print(f\"üîÑ Training started... (This may take a while)\")\n",
    "        \n",
    "        with open(log_file, 'w', encoding='utf-8') as log_f:\n",
    "            process = subprocess.Popen(\n",
    "                cmd, \n",
    "                stdout=subprocess.PIPE, \n",
    "                stderr=subprocess.STDOUT,\n",
    "                universal_newlines=True,\n",
    "                bufsize=1\n",
    "            )\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á output ‡πÅ‡∏ö‡∏ö real-time\n",
    "            line_count = 0\n",
    "            for line in iter(process.stdout.readline, ''):\n",
    "                line_count += 1\n",
    "                print(line.strip())\n",
    "                log_f.write(line)\n",
    "                log_f.flush()\n",
    "                \n",
    "                # ‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏™‡∏î‡∏á output ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å 100 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ notebook ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                if line_count > 100:\n",
    "                    print(\"\\\\n... (Training continues, check log file for full output)\")\n",
    "                    break\n",
    "            \n",
    "            # ‡∏£‡∏≠‡πÉ‡∏´‡πâ process ‡πÄ‡∏™‡∏£‡πá‡∏à (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏û‡∏±‡∏Å)\n",
    "            process.wait()\n",
    "            \n",
    "            if process.returncode == 0:\n",
    "                print(\"‚úÖ Training completed successfully!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ùå Training failed with return code: {process.returncode}\")\n",
    "                return False\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\\\n‚èπÔ∏è Training interrupted by user\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed with error: {e}\")\n",
    "        return False\n",
    "\n",
    "def monitor_recognition_training_progress(model_save_dir):\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Recognition\n",
    "    \"\"\"\n",
    "    print(f\"üìä Monitoring training progress in: {model_save_dir}\")\n",
    "    \n",
    "    if not os.path.exists(model_save_dir):\n",
    "        print(\"üìÅ Model save directory doesn't exist yet.\")\n",
    "        return\n",
    "    \n",
    "    # ‡∏´‡∏≤ checkpoint files\n",
    "    checkpoints = []\n",
    "    for file in os.listdir(model_save_dir):\n",
    "        if file.endswith('.pdparams'):\n",
    "            checkpoint_path = os.path.join(model_save_dir, file)\n",
    "            mtime = os.path.getmtime(checkpoint_path)\n",
    "            size = os.path.getsize(checkpoint_path) / (1024 * 1024)  # MB\n",
    "            checkpoints.append({\n",
    "                'name': file,\n",
    "                'path': checkpoint_path,\n",
    "                'modified': datetime.fromtimestamp(mtime),\n",
    "                'size_mb': size\n",
    "            })\n",
    "    \n",
    "    if checkpoints:\n",
    "        checkpoints.sort(key=lambda x: x['modified'], reverse=True)\n",
    "        print(f\"\\\\nüéØ Found {len(checkpoints)} Recognition model checkpoints:\")\n",
    "        \n",
    "        for i, checkpoint in enumerate(checkpoints[:5]):  # ‡πÅ‡∏™‡∏î‡∏á 5 ‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "            print(f\"   {i+1}. {checkpoint['name']}\")\n",
    "            print(f\"      Size: {checkpoint['size_mb']:.1f} MB\")\n",
    "            print(f\"      Modified: {checkpoint['modified']}\")\n",
    "        \n",
    "        if len(checkpoints) > 5:\n",
    "            print(f\"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(checkpoints) - 5} checkpoints\")\n",
    "            \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• latest checkpoint\n",
    "        latest = checkpoints[0]\n",
    "        print(f\"\\\\nüìà Latest checkpoint: {latest['name']}\")\n",
    "        print(f\"   Created: {latest['modified']}\")\n",
    "        print(f\"   Size: {latest['size_mb']:.1f} MB\")\n",
    "        \n",
    "    else:\n",
    "        print(\"üì≠ No checkpoints found yet.\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö log file\n",
    "    log_file = os.path.join(model_save_dir, \"training.log\")\n",
    "    if os.path.exists(log_file):\n",
    "        print(f\"\\\\nüìù Training log preview (last 10 lines):\")\n",
    "        try:\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines[-10:]:\n",
    "                    print(f\"   {line.strip()}\")\n",
    "        except:\n",
    "            print(\"   (Unable to read log file)\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô\n",
    "print(\"üîç Pre-training checklist:\")\n",
    "checklist_items = [\n",
    "    (\"PaddleOCR repository\", os.path.exists(PADDLEOCR_DIR)),\n",
    "    (\"Training script\", os.path.exists(os.path.join(PADDLEOCR_DIR, \"tools\", \"train.py\"))),\n",
    "    (\"Configuration file\", os.path.exists(output_config_path)),\n",
    "    (\"Train annotation\", os.path.exists(train_annotation_path)),\n",
    "    (\"Eval annotation\", os.path.exists(eval_annotation_path)),\n",
    "    (\"Model save directory\", os.path.exists(LOCAL_RECOGNITION_MODEL_DIR)),\n",
    "    (\"GPU available\", paddle.is_compiled_with_cuda())\n",
    "]\n",
    "\n",
    "all_ready = True\n",
    "for item_name, is_ready in checklist_items:\n",
    "    status = \"‚úÖ\" if is_ready else \"‚ùå\"\n",
    "    print(f\"   {status} {item_name}\")\n",
    "    if not is_ready:\n",
    "        all_ready = False\n",
    "\n",
    "if all_ready:\n",
    "    print(\"\\\\nüöÄ All checks passed! Ready to start training.\")\n",
    "    \n",
    "    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô (‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á)\n",
    "    print(f\"\\\\nüìã Training command that will be executed:\")\n",
    "    print(f\"   cd {PADDLEOCR_DIR}\")\n",
    "    print(f\"   python tools/train.py -c {output_config_path}\")\n",
    "    \n",
    "    # ‡∏ñ‡∏≤‡∏° user ‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "    print(f\"\\\\n‚ö†Ô∏è  Note: Training will take time and GPU resources.\")\n",
    "    print(f\"   Uncomment the following lines to start actual training:\")\n",
    "    print(f\"   # training_success = start_recognition_training(output_config_path)\")\n",
    "    print(f\"   # monitor_recognition_training_progress(LOCAL_RECOGNITION_MODEL_DIR)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\\\n‚ùå Some requirements are not met. Please fix issues before training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdc8fa",
   "metadata": {},
   "source": [
    "### üöÄ Ready-to-Execute Training Commands\n",
    "\n",
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f80db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üéØ TRAINING EXECUTION OPTIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üöÄ RECOGNITION TRAINING EXECUTION OPTIONS\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "if all_ready:\n",
    "    print(\"\\n‚úÖ All prerequisites are ready!\")\n",
    "    \n",
    "    # Option 1: Quick demo training (short)\n",
    "    print(f\"\\nüöÄ OPTION 1: Quick Demo Training (2-3 epochs)\")\n",
    "    print(f\"   Perfect for testing and verification\")\n",
    "    print(f\"   Uncomment to run:\")\n",
    "    print(f\"   # quick_config = create_quick_demo_config()\")\n",
    "    print(f\"   # training_success = start_recognition_training(quick_config)\")\n",
    "    \n",
    "    # Option 2: Full production training\n",
    "    print(f\"\\nüè≠ OPTION 2: Full Production Training\")\n",
    "    print(f\"   Complete training with many epochs\")\n",
    "    print(f\"   Uncomment to run:\")\n",
    "    print(f\"   # training_success = start_recognition_training(output_config_path)\")\n",
    "    print(f\"   # monitor_recognition_training_progress(LOCAL_RECOGNITION_MODEL_DIR)\")\n",
    "    \n",
    "    # Option 3: Manual command line\n",
    "    print(f\"\\nüíª OPTION 3: Manual Command Line Execution\")\n",
    "    print(f\"   Run in terminal for full control:\")\n",
    "    print(f\"   cd {PADDLEOCR_DIR}\")\n",
    "    print(f\"   python tools/train.py -c {output_config_path}\")\n",
    "    \n",
    "    # Option 4: Background training\n",
    "    print(f\"\\nüîÑ OPTION 4: Background Training with Monitoring\")\n",
    "    print(f\"   Training runs in background, periodic monitoring\")\n",
    "    print(f\"   # start_background_recognition_training()\")\n",
    "    \n",
    "    print(f\"\\n‚ö° CHOOSE YOUR TRAINING METHOD:\")\n",
    "    print(f\"   1. For testing: Use Option 1 (Quick Demo)\")\n",
    "    print(f\"   2. For production: Use Option 2 (Full Training)\")\n",
    "    print(f\"   3. For control: Use Option 3 (Manual)\")\n",
    "    print(f\"   4. For long runs: Use Option 4 (Background)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå Prerequisites not met. Please complete setup first.\")\n",
    "    print(\"    Check previous sections for missing requirements.\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*55)\n",
    "\n",
    "# Quick demo config function\n",
    "def create_quick_demo_config():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo training (epochs ‡∏ô‡πâ‡∏≠‡∏¢)\n",
    "    \"\"\"\n",
    "    # Copy config ‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç epochs\n",
    "    demo_config_path = output_config_path.replace('.yml', '_demo.yml')\n",
    "    \n",
    "    with open(output_config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # ‡∏•‡∏î epochs ‡πÄ‡∏û‡∏∑‡πà‡∏≠ demo\n",
    "    config['Global']['epoch_num'] = 3\n",
    "    config['Global']['eval_batch_step'] = [0, 5, 10]\n",
    "    config['Global']['save_epoch_step'] = 1\n",
    "    \n",
    "    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå config ‡πÉ‡∏´‡∏°‡πà\n",
    "    with open(demo_config_path, 'w', encoding='utf-8') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    print(f\"‚úÖ Created demo config: {demo_config_path}\")\n",
    "    print(f\"   ‚Ä¢ Epochs: 3 (vs original {config.get('Global', {}).get('epoch_num', 'unknown')})\")\n",
    "    print(f\"   ‚Ä¢ Quick evaluation and saving\")\n",
    "    \n",
    "    return demo_config_path\n",
    "\n",
    "def start_background_recognition_training():\n",
    "    \"\"\"\n",
    "    ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏ö‡∏ö background ‡∏û‡∏£‡πâ‡∏≠‡∏° monitoring\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Starting background Recognition training...\")\n",
    "    \n",
    "    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏ö‡∏ö background\n",
    "    log_file = os.path.join(LOCAL_RECOGNITION_MODEL_DIR, \"training.log\")\n",
    "    \n",
    "    train_cmd = [\n",
    "        sys.executable, \n",
    "        os.path.join(PADDLEOCR_DIR, \"tools\", \"train.py\"), \n",
    "        \"-c\", output_config_path\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Start background process\n",
    "        with open(log_file, 'w') as log_f:\n",
    "            process = subprocess.Popen(\n",
    "                train_cmd,\n",
    "                cwd=PADDLEOCR_DIR,\n",
    "                stdout=log_f,\n",
    "                stderr=subprocess.STDOUT\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úÖ Training started in background (PID: {process.pid})\")\n",
    "        print(f\"üìä Monitor log: tail -f {log_file}\")\n",
    "        print(f\"‚èπÔ∏è  Stop training: kill {process.pid}\")\n",
    "        \n",
    "        return process\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to start background training: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ready-to-execute command examples\n",
    "print(f\"\\nüìã READY-TO-EXECUTE EXAMPLES:\")\n",
    "print(f\"\\n# Quick 3-epoch demo:\")\n",
    "print(f\"# demo_config = create_quick_demo_config()\")\n",
    "print(f\"# start_recognition_training(demo_config)\")\n",
    "print(f\"\\n# Full production training:\")\n",
    "print(f\"# start_recognition_training(output_config_path)\")\n",
    "print(f\"\\n# Background training:\")\n",
    "print(f\"# bg_process = start_background_recognition_training()\")\n",
    "print(f\"\\n# Monitor progress:\")\n",
    "print(f\"# monitor_recognition_training_progress(LOCAL_RECOGNITION_MODEL_DIR)\")\n",
    "\n",
    "print(f\"\\nüí° TIP: Start with quick demo to verify everything works!\")\n",
    "print(f\"    Then proceed to full training for production models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6789e",
   "metadata": {},
   "source": [
    "## 9. Sync Recognition Model Checkpoints to S3\n",
    "\n",
    "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Recognition model checkpoints (‡πÑ‡∏ü‡∏•‡πå .pdparams ‡πÅ‡∏•‡∏∞ .pdopt) ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_recognition_checkpoints_to_s3(local_model_dir, s3_bucket, s3_model_prefix):\n",
    "    \"\"\"\n",
    "    Sync Recognition model checkpoints ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3\n",
    "    ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå .pdparams ‡πÅ‡∏•‡∏∞ .pdopt ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    if not os.path.exists(local_model_dir):\n",
    "        print(f\"‚ùå Model directory doesn't exist: {local_model_dir}\")\n",
    "        return []\n",
    "    \n",
    "    uploaded_files = []\n",
    "    \n",
    "    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå model ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î\n",
    "    for root, dirs, files in os.walk(local_model_dir):\n",
    "        for file in files:\n",
    "            # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå Recognition model\n",
    "            if file.endswith(('.pdparams', '.pdopt', '.states', '.yml', '.log')):\n",
    "                local_file_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(local_file_path, local_model_dir)\n",
    "                s3_key = f\"{s3_model_prefix}/{relative_path}\"\n",
    "                \n",
    "                try:\n",
    "                    print(f\"üì§ Uploading: {relative_path} -> s3://{s3_bucket}/{s3_key}\")\n",
    "                    s3_client.upload_file(local_file_path, s3_bucket, s3_key)\n",
    "                    \n",
    "                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå\n",
    "                    file_size = os.path.getsize(local_file_path) / (1024 * 1024)  # MB\n",
    "                    uploaded_files.append({\n",
    "                        'local_path': local_file_path,\n",
    "                        's3_key': s3_key,\n",
    "                        'size_mb': file_size,\n",
    "                        'type': 'recognition_model' if file.endswith('.pdparams') else 'other'\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Failed to upload {file}: {e}\")\n",
    "    \n",
    "    print(f\"\\\\n‚úÖ Uploaded {len(uploaded_files)} files to S3\")\n",
    "    \n",
    "    # ‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î\n",
    "    model_files = [f for f in uploaded_files if f['type'] == 'recognition_model']\n",
    "    other_files = [f for f in uploaded_files if f['type'] == 'other']\n",
    "    \n",
    "    if model_files:\n",
    "        print(f\"\\\\nüéØ Recognition Model Files ({len(model_files)}):\")\n",
    "        for file_info in model_files:\n",
    "            print(f\"   üìä {os.path.basename(file_info['s3_key'])} ({file_info['size_mb']:.1f} MB)\")\n",
    "    \n",
    "    if other_files:\n",
    "        print(f\"\\\\nüìã Other Files ({len(other_files)}):\")\n",
    "        for file_info in other_files[:5]:  # ‡πÅ‡∏™‡∏î‡∏á 5 ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å\n",
    "            print(f\"   üìÑ {os.path.basename(file_info['s3_key'])} ({file_info['size_mb']:.1f} MB)\")\n",
    "        if len(other_files) > 5:\n",
    "            print(f\"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(other_files) - 5} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "    \n",
    "    return uploaded_files\n",
    "\n",
    "def download_recognition_checkpoints_from_s3(s3_bucket, s3_model_prefix, local_model_dir):\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Recognition model checkpoints ‡∏à‡∏≤‡∏Å S3\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    downloaded_files = []\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á directory ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ\n",
    "    os.makedirs(local_model_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å S3\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        pages = paginator.paginate(Bucket=s3_bucket, Prefix=s3_model_prefix)\n",
    "        \n",
    "        for page in pages:\n",
    "            if 'Contents' in page:\n",
    "                for obj in page['Contents']:\n",
    "                    s3_key = obj['Key']\n",
    "                    \n",
    "                    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Recognition model\n",
    "                    if s3_key.endswith(('.pdparams', '.pdopt', '.states', '.yml', '.log')):\n",
    "                        relative_path = s3_key[len(s3_model_prefix):].lstrip('/')\n",
    "                        local_file_path = os.path.join(local_model_dir, relative_path)\n",
    "                        \n",
    "                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á directory ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "                        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "                        \n",
    "                        print(f\"üì• Downloading: s3://{s3_bucket}/{s3_key} -> {relative_path}\")\n",
    "                        s3_client.download_file(s3_bucket, s3_key, local_file_path)\n",
    "                        downloaded_files.append(local_file_path)\n",
    "        \n",
    "        print(f\"‚úÖ Downloaded {len(downloaded_files)} files from S3\")\n",
    "        return downloaded_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading checkpoints from S3: {e}\")\n",
    "        return []\n",
    "\n",
    "def list_s3_recognition_checkpoints(s3_bucket, s3_model_prefix):\n",
    "    \"\"\"\n",
    "    ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Recognition checkpoints ‡πÉ‡∏ô S3\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        response = s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=s3_model_prefix)\n",
    "        \n",
    "        if 'Contents' in response:\n",
    "            checkpoints = []\n",
    "            for obj in response['Contents']:\n",
    "                if obj['Key'].endswith(('.pdparams', '.pdopt', '.states')):\n",
    "                    checkpoints.append({\n",
    "                        'key': obj['Key'],\n",
    "                        'size': obj['Size'],\n",
    "                        'modified': obj['LastModified']\n",
    "                    })\n",
    "            \n",
    "            if checkpoints:\n",
    "                print(f\"üìã Recognition checkpoints in s3://{s3_bucket}/{s3_model_prefix}:\")\n",
    "                for checkpoint in sorted(checkpoints, key=lambda x: x['modified'], reverse=True):\n",
    "                    size_mb = checkpoint['size'] / (1024 * 1024)\n",
    "                    print(f\"   üéØ {os.path.basename(checkpoint['key'])} ({size_mb:.1f} MB, {checkpoint['modified']})\")\n",
    "                return checkpoints\n",
    "            else:\n",
    "                print(\"üì≠ No recognition checkpoints found in S3.\")\n",
    "                return []\n",
    "        else:\n",
    "            print(\"üì≠ No objects found in S3 bucket with the specified prefix.\")\n",
    "            return []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing S3 checkpoints: {e}\")\n",
    "        return []\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö checkpoint files ‡πÉ‡∏ô local directory\n",
    "print(\"üîç Checking for Recognition model files in local directory...\")\n",
    "monitor_recognition_training_progress(LOCAL_RECOGNITION_MODEL_DIR)\n",
    "\n",
    "# ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î checkpoints ‡πÑ‡∏õ‡∏¢‡∏±‡∏á S3 (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
    "print(f\"\\\\nüì§ Syncing Recognition checkpoints to S3...\")\n",
    "uploaded_files = sync_recognition_checkpoints_to_s3(\n",
    "    LOCAL_RECOGNITION_MODEL_DIR, \n",
    "    S3_BUCKET, \n",
    "    S3_RECOGNITION_MODEL_PREFIX\n",
    ")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ checkpoints ‡πÉ‡∏ô S3\n",
    "print(f\"\\\\nüìã Listing Recognition checkpoints in S3...\")\n",
    "s3_checkpoints = list_s3_recognition_checkpoints(S3_BUCKET, S3_RECOGNITION_MODEL_PREFIX)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á summary\n",
    "print(f\"\\\\nüìä Recognition Model Sync Summary:\")\n",
    "print(f\"   Local model directory: {LOCAL_RECOGNITION_MODEL_DIR}\")\n",
    "print(f\"   S3 bucket: s3://{S3_BUCKET}/{S3_RECOGNITION_MODEL_PREFIX}\")\n",
    "print(f\"   Files uploaded: {len(uploaded_files)}\")\n",
    "print(f\"   Recognition checkpoints in S3: {len(s3_checkpoints)}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
    "print(f\"\\\\nüí° Tips:\")\n",
    "print(f\"   - Recognition model files (.pdparams) contain the trained weights\")\n",
    "print(f\"   - Optimizer files (.pdopt) contain optimizer state for resuming training\")\n",
    "print(f\"   - Use the latest .pdparams file for inference\")\n",
    "print(f\"   - Download checkpoints for deployment or further training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c45454",
   "metadata": {},
   "source": [
    "## 10. Monitor Training Progress and Model Output\n",
    "\n",
    "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee059f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_gpu_usage():\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° GPU usage ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu', \n",
    "                               '--format=csv,noheader,nounits'], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            lines = result.stdout.strip().split('\\\\n')\n",
    "            print(f\"üéÆ GPU Status:\")\n",
    "            for i, line in enumerate(lines):\n",
    "                gpu_util, mem_used, mem_total, temp = line.split(', ')\n",
    "                mem_usage_pct = (int(mem_used) / int(mem_total)) * 100\n",
    "                print(f\"   GPU {i}: {gpu_util}% utilization, {mem_usage_pct:.1f}% memory ({mem_used}/{mem_total} MB), {temp}¬∞C\")\n",
    "        else:\n",
    "            print(\"‚ùå Could not get GPU status\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error monitoring GPU: {e}\")\n",
    "\n",
    "def analyze_training_logs(log_file_path):\n",
    "    \"\"\"\n",
    "    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå log files ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Recognition\n",
    "    \"\"\"\n",
    "    if not os.path.exists(log_file_path):\n",
    "        print(f\"üì≠ Log file not found: {log_file_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Analyzing training logs: {log_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(log_file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å logs\n",
    "        loss_values = []\n",
    "        accuracy_values = []\n",
    "        lr_values = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # ‡∏´‡∏≤ loss values\n",
    "            if 'loss:' in line.lower():\n",
    "                try:\n",
    "                    loss_part = line.split('loss:')[1].split()[0]\n",
    "                    loss_val = float(loss_part.replace(',', ''))\n",
    "                    loss_values.append(loss_val)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # ‡∏´‡∏≤ accuracy values\n",
    "            if 'acc:' in line.lower():\n",
    "                try:\n",
    "                    acc_part = line.split('acc:')[1].split()[0]\n",
    "                    acc_val = float(acc_part.replace(',', ''))\n",
    "                    accuracy_values.append(acc_val)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # ‡∏´‡∏≤ learning rate\n",
    "            if 'lr:' in line.lower():\n",
    "                try:\n",
    "                    lr_part = line.split('lr:')[1].split()[0]\n",
    "                    lr_val = float(lr_part.replace(',', ''))\n",
    "                    lr_values.append(lr_val)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥\n",
    "        print(f\"\\\\nüìà Training Statistics:\")\n",
    "        \n",
    "        if loss_values:\n",
    "            print(f\"   Loss: {len(loss_values)} values\")\n",
    "            print(f\"     Initial: {loss_values[0]:.4f}\")\n",
    "            print(f\"     Final: {loss_values[-1]:.4f}\")\n",
    "            print(f\"     Best: {min(loss_values):.4f}\")\n",
    "        \n",
    "        if accuracy_values:\n",
    "            print(f\"   Accuracy: {len(accuracy_values)} values\")\n",
    "            print(f\"     Initial: {accuracy_values[0]:.4f}\")\n",
    "            print(f\"     Final: {accuracy_values[-1]:.4f}\")\n",
    "            print(f\"     Best: {max(accuracy_values):.4f}\")\n",
    "        \n",
    "        if lr_values:\n",
    "            print(f\"   Learning Rate: {len(lr_values)} values\")\n",
    "            print(f\"     Initial: {lr_values[0]:.6f}\")\n",
    "            print(f\"     Final: {lr_values[-1]:.6f}\")\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ 10 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î\n",
    "        print(f\"\\\\nüìù Recent log entries:\")\n",
    "        for line in lines[-10:]:\n",
    "            print(f\"   {line.strip()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing logs: {e}\")\n",
    "\n",
    "def verify_recognition_model_output():\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ Recognition model ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "    \"\"\"\n",
    "    print(f\"üîç Verifying Recognition model output...\")\n",
    "    \n",
    "    model_files = []\n",
    "    for root, dirs, files in os.walk(LOCAL_RECOGNITION_MODEL_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdparams'):\n",
    "                model_files.append({\n",
    "                    'name': file,\n",
    "                    'path': os.path.join(root, file),\n",
    "                    'size': os.path.getsize(os.path.join(root, file)) / (1024 * 1024)\n",
    "                })\n",
    "    \n",
    "    if model_files:\n",
    "        print(f\"‚úÖ Found {len(model_files)} Recognition model files:\")\n",
    "        for model in sorted(model_files, key=lambda x: x['name']):\n",
    "            print(f\"   üéØ {model['name']} ({model['size']:.1f} MB)\")\n",
    "            \n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Recognition model ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "            if any(keyword in model['name'].lower() for keyword in ['rec', 'recognition', 'crnn', 'svtr']):\n",
    "                print(f\"      ‚úì Confirmed as Recognition model\")\n",
    "            else:\n",
    "                print(f\"      ‚ö†Ô∏è  Model type unclear from filename\")\n",
    "        \n",
    "        # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "        latest_model = max(model_files, key=lambda x: os.path.getmtime(x['path']))\n",
    "        print(f\"\\\\nüåü Recommended model for inference:\")\n",
    "        print(f\"   üìä {latest_model['name']}\")\n",
    "        print(f\"   üìÅ {latest_model['path']}\")\n",
    "        print(f\"   üìè {latest_model['size']:.1f} MB\")\n",
    "        \n",
    "        return model_files\n",
    "    else:\n",
    "        print(\"‚ùå No Recognition model files (.pdparams) found!\")\n",
    "        print(\"   Make sure training completed successfully\")\n",
    "        return []\n",
    "\n",
    "def create_training_summary():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Recognition\n",
    "    \"\"\"\n",
    "    print(f\"\\\\n\" + \"=\"*60)\n",
    "    print(f\"üìã RECOGNITION TRAINING SUMMARY\")\n",
    "    print(f\"=\"*60)\n",
    "    \n",
    "    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô\n",
    "    print(f\"\\\\nüéØ Training Configuration:\")\n",
    "    print(f\"   Target: Text Recognition Only\")\n",
    "    print(f\"   Architecture: CRNN (MobileNetV3 + BiLSTM + CTC)\")\n",
    "    print(f\"   Config file: {output_config_path}\")\n",
    "    print(f\"   Model save directory: {LOCAL_RECOGNITION_MODEL_DIR}\")\n",
    "    \n",
    "    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "    print(f\"\\\\nüìä Training Data:\")\n",
    "    print(f\"   Train annotation: {train_annotation_path}\")\n",
    "    print(f\"   Eval annotation: {eval_annotation_path}\")\n",
    "    print(f\"   Data format: image_path\\\\ttext_content\")\n",
    "    \n",
    "    # GPU information\n",
    "    print(f\"\\\\nüéÆ Hardware:\")\n",
    "    print(f\"   GPU available: {paddle.is_compiled_with_cuda()}\")\n",
    "    if paddle.is_compiled_with_cuda():\n",
    "        print(f\"   GPU count: {paddle.device.cuda.device_count()}\")\n",
    "    \n",
    "    monitor_gpu_usage()\n",
    "    \n",
    "    # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    print(f\"\\\\nüéØ Results:\")\n",
    "    model_files = verify_recognition_model_output()\n",
    "    \n",
    "    # S3 sync status\n",
    "    print(f\"\\\\n‚òÅÔ∏è  S3 Storage:\")\n",
    "    print(f\"   Bucket: s3://{S3_BUCKET}\")\n",
    "    print(f\"   Recognition data: {S3_RECOGNITION_DATA_PREFIX}/\")\n",
    "    print(f\"   Recognition models: {S3_RECOGNITION_MODEL_PREFIX}/\")\n",
    "    \n",
    "    # Training logs\n",
    "    log_file = os.path.join(LOCAL_RECOGNITION_MODEL_DIR, \"training.log\")\n",
    "    if os.path.exists(log_file):\n",
    "        print(f\"\\\\nüìù Training Log Analysis:\")\n",
    "        analyze_training_logs(log_file)\n",
    "    \n",
    "    # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "    print(f\"\\\\nüöÄ Next Steps:\")\n",
    "    if model_files:\n",
    "        print(f\"   1. Use the latest .pdparams file for inference\")\n",
    "        print(f\"   2. Download model from S3 for deployment\")\n",
    "        print(f\"   3. Test recognition with sample images\")\n",
    "        print(f\"   4. Deploy model using PaddleOCR inference tools\")\n",
    "    else:\n",
    "        print(f\"   1. Check training logs for errors\")\n",
    "        print(f\"   2. Verify annotation file format\")\n",
    "        print(f\"   3. Restart training if necessary\")\n",
    "    \n",
    "    print(f\"\\\\n\" + \"=\"*60)\n",
    "\n",
    "# ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•\n",
    "print(\"üîç Starting final monitoring and summary...\")\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° GPU usage\n",
    "monitor_gpu_usage()\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö training progress\n",
    "monitor_recognition_training_progress(LOCAL_RECOGNITION_MODEL_DIR)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "create_training_summary()\n",
    "\n",
    "print(\"\\\\n‚úÖ Recognition training notebook completed!\")\n",
    "print(\"\\\\nüí° Remember:\")\n",
    "print(\"   - This notebook focuses on Text Recognition only\")\n",
    "print(\"   - Output files are .pdparams Recognition models\")\n",
    "print(\"   - Use tools/train_rec.py or tools/train.py for actual training\")\n",
    "print(\"   - Check docs/problem-log.md before troubleshooting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3952955",
   "metadata": {},
   "source": [
    "## 11. Test Recognition Model (Optional)\n",
    "\n",
    "‡∏ó‡∏î‡∏™‡∏≠‡∏ö Recognition model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recognition_model_inference(model_path, test_image_path, config_path):\n",
    "    \"\"\"\n",
    "    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Recognition model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "    \"\"\"\n",
    "    print(f\"üß™ Testing Recognition model inference...\")\n",
    "    print(f\"   Model: {model_path}\")\n",
    "    print(f\"   Test image: {test_image_path}\")\n",
    "    print(f\"   Config: {config_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model file not found: {model_path}\")\n",
    "        return False\n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"‚ùå Test image not found: {test_image_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference\n",
    "        inference_cmd = [\n",
    "            \"python\", \"tools/infer_rec.py\",\n",
    "            \"-c\", config_path,\n",
    "            \"-o\", f\"Global.pretrained_model={model_path}\",\n",
    "            \"-o\", f\"Global.infer_img={test_image_path}\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"üöÄ Running recognition inference...\")\n",
    "        print(f\"   Command: {' '.join(inference_cmd)}\")\n",
    "        \n",
    "        # ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á inference\n",
    "        result = subprocess.run(\n",
    "            inference_cmd,\n",
    "            cwd=PADDLEOCR_DIR,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=300\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ Inference completed successfully!\")\n",
    "            print(f\"üìä Recognition results:\")\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "            output_lines = result.stdout.strip().split('\\n')\n",
    "            for line in output_lines[-10:]:  # ‡πÅ‡∏™‡∏î‡∏á 10 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Inference failed!\")\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚è∞ Inference timed out!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during inference: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_sample_test_images():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö Recognition\n",
    "    \"\"\"\n",
    "    print(f\"üé® Creating sample test images for recognition...\")\n",
    "    \n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    import numpy as np\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö test images\n",
    "    test_dir = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"test_samples\")\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "    test_texts = [\n",
    "        \"Hello World\",\n",
    "        \"PaddleOCR\",\n",
    "        \"Recognition Test\",\n",
    "        \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ\",\n",
    "        \"1234567890\",\n",
    "        \"ABC123\"\n",
    "    ]\n",
    "    \n",
    "    created_images = []\n",
    "    \n",
    "    for i, text in enumerate(test_texts):\n",
    "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏≤‡∏ß\n",
    "        img_width, img_height = 200, 50\n",
    "        img = Image.new('RGB', (img_width, img_height), color='white')\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "        try:\n",
    "            # ‡πÉ‡∏ä‡πâ font ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô\n",
    "            font_size = 24\n",
    "            bbox = draw.textbbox((0, 0), text)\n",
    "            text_width = bbox[2] - bbox[0]\n",
    "            text_height = bbox[3] - bbox[1]\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á\n",
    "            x = (img_width - text_width) // 2\n",
    "            y = (img_height - text_height) // 2\n",
    "            \n",
    "            draw.text((x, y), text, fill='black')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not draw text '{text}': {e}\")\n",
    "            continue\n",
    "        \n",
    "        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "        img_path = os.path.join(test_dir, f\"test_{i+1:02d}.jpg\")\n",
    "        img.save(img_path)\n",
    "        created_images.append({\n",
    "            'path': img_path,\n",
    "            'text': text,\n",
    "            'filename': f\"test_{i+1:02d}.jpg\"\n",
    "        })\n",
    "        \n",
    "        print(f\"   ‚úì Created: {img_path} -> '{text}'\")\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(created_images)} test images in: {test_dir}\")\n",
    "    return created_images, test_dir\n",
    "\n",
    "def run_comprehensive_recognition_test():\n",
    "    \"\"\"\n",
    "    ‡∏£‡∏±‡∏ô comprehensive test ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition model\n",
    "    \"\"\"\n",
    "    print(f\"üß™ Running comprehensive Recognition model test...\")\n",
    "    \n",
    "    # ‡∏´‡∏≤ model file ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "    model_files = []\n",
    "    for root, dirs, files in os.walk(LOCAL_RECOGNITION_MODEL_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdparams'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                model_files.append({\n",
    "                    'path': full_path,\n",
    "                    'name': file,\n",
    "                    'mtime': os.path.getmtime(full_path)\n",
    "                })\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"‚ùå No Recognition model files found!\")\n",
    "        return False\n",
    "    \n",
    "    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "    latest_model = max(model_files, key=lambda x: x['mtime'])\n",
    "    model_path = latest_model['path'].replace('.pdparams', '')  # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ extension\n",
    "    \n",
    "    print(f\"üéØ Using model: {latest_model['name']}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "    test_images, test_dir = create_sample_test_images()\n",
    "    \n",
    "    if not test_images:\n",
    "        print(f\"‚ùå No test images created!\")\n",
    "        return False\n",
    "    \n",
    "    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "    success_count = 0\n",
    "    for test_img in test_images[:3]:  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö 3 ‡∏£‡∏π‡∏õ‡πÅ‡∏£‡∏Å\n",
    "        print(f\"\\\\nüîç Testing with: {test_img['filename']} (expected: '{test_img['text']}')\")\n",
    "        \n",
    "        success = test_recognition_model_inference(\n",
    "            model_path=model_path,\n",
    "            test_image_path=test_img['path'],\n",
    "            config_path=output_config_path\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            success_count += 1\n",
    "    \n",
    "    print(f\"\\\\nüìä Test Results:\")\n",
    "    print(f\"   Tests run: {min(len(test_images), 3)}\")\n",
    "    print(f\"   Successful: {success_count}\")\n",
    "    print(f\"   Success rate: {(success_count / min(len(test_images), 3)) * 100:.1f}%\")\n",
    "    \n",
    "    return success_count > 0\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö (optional)\n",
    "print(\"üß™ Recognition Model Testing Section\")\n",
    "print(\"   This section allows you to test your trained Recognition model\")\n",
    "print(\"   Uncomment the following lines to run tests:\")\n",
    "print(\"   # test_success = run_comprehensive_recognition_test()\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô model\n",
    "def create_inference_guide():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Recognition model\n",
    "    \"\"\"\n",
    "    print(f\"\\\\nüìñ RECOGNITION MODEL INFERENCE GUIDE\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    # ‡∏´‡∏≤ model ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
    "    model_files = []\n",
    "    for root, dirs, files in os.walk(LOCAL_RECOGNITION_MODEL_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdparams'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                model_files.append({\n",
    "                    'path': full_path,\n",
    "                    'name': file,\n",
    "                    'size_mb': os.path.getsize(full_path) / (1024 * 1024)\n",
    "                })\n",
    "    \n",
    "    if model_files:\n",
    "        recommended_model = max(model_files, key=lambda x: os.path.getmtime(x['path']))\n",
    "        \n",
    "        print(f\"\\\\nüéØ Recommended Model:\")\n",
    "        print(f\"   File: {recommended_model['name']}\")\n",
    "        print(f\"   Path: {recommended_model['path']}\")\n",
    "        print(f\"   Size: {recommended_model['size_mb']:.1f} MB\")\n",
    "        \n",
    "        print(f\"\\\\nüíª Command Line Usage:\")\n",
    "        model_path_no_ext = recommended_model['path'].replace('.pdparams', '')\n",
    "        print(f\"   cd {PADDLEOCR_DIR}\")\n",
    "        print(f\"   python tools/infer_rec.py \\\\\\\\\")\n",
    "        print(f\"     -c {output_config_path} \\\\\\\\\")\n",
    "        print(f\"     -o Global.pretrained_model={model_path_no_ext} \\\\\\\\\")\n",
    "        print(f\"     -o Global.infer_img=path/to/your/image.jpg\")\n",
    "        \n",
    "        print(f\"\\\\nüêç Python API Usage:\")\n",
    "        print(f\"   from paddleocr import PaddleOCR\")\n",
    "        print(f\"   ocr = PaddleOCR(\")\n",
    "        print(f\"       use_angle_cls=False,\")\n",
    "        print(f\"       lang='en',  # or 'ch' for Chinese\")\n",
    "        print(f\"       rec_model_dir='{os.path.dirname(model_path_no_ext)}'\")\n",
    "        print(f\"   )\")\n",
    "        print(f\"   result = ocr.ocr('path/to/your/image.jpg', det=False)\")\n",
    "        \n",
    "        print(f\"\\\\n‚òÅÔ∏è  S3 Model Location:\")\n",
    "        print(f\"   s3://{S3_BUCKET}/{S3_RECOGNITION_MODEL_PREFIX}/\")\n",
    "        \n",
    "        print(f\"\\\\nüìã Model Deployment Tips:\")\n",
    "        print(f\"   1. Download .pdparams file from S3\")\n",
    "        print(f\"   2. Use with PaddleOCR inference tools\")\n",
    "        print(f\"   3. For production, consider model optimization\")\n",
    "        print(f\"   4. Test with various image types and sizes\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\\\n‚ùå No model files found for inference guide\")\n",
    "\n",
    "create_inference_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ba3de",
   "metadata": {},
   "source": [
    "## üéØ Final Summary and Next Steps\n",
    "\n",
    "‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddleOCR Recognition Training ‡∏ö‡∏ô SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ\" + \"=\"*70)\n",
    "print(\"  PADDLEOCR RECOGNITION TRAINING - FINAL SUMMARY\")\n",
    "print(\"=\"*77)\n",
    "\n",
    "print(f\"\\n‚úÖ COMPLETED SETUP:\")\n",
    "print(f\"   üìã Environment verification and GPU check\")\n",
    "print(f\"   üì¶ PaddleOCR repository cloned and configured\")\n",
    "print(f\"   ‚òÅÔ∏è  S3 integration setup and tested\")\n",
    "print(f\"   üìù Recognition annotation format validation\")\n",
    "print(f\"   üîß Training configuration prepared\")\n",
    "print(f\"   üìä Monitoring and checkpoint sync ready\")\n",
    "\n",
    "print(f\"\\nüéØ RECOGNITION TRAINING FOCUS:\")\n",
    "print(f\"   ‚úì Text Recognition only (no detection)\")\n",
    "print(f\"   ‚úì CRNN architecture (MobileNetV3 + BiLSTM + CTC)\")\n",
    "print(f\"   ‚úì Tab-separated annotation format: image_path\\\\ttext_content\")\n",
    "print(f\"   ‚úì Output: .pdparams Recognition model files\")\n",
    "print(f\"   ‚úì S3 integration for data and model storage\")\n",
    "\n",
    "print(f\"\\nüìÅ KEY DIRECTORIES:\")\n",
    "print(f\"   üìÇ PaddleOCR repo: {PADDLEOCR_DIR}\")\n",
    "print(f\"   üìÇ Recognition data: {LOCAL_RECOGNITION_DATA_DIR}\")\n",
    "print(f\"   üìÇ Model output: {LOCAL_RECOGNITION_MODEL_DIR}\")\n",
    "print(f\"   üìÇ Config files: {LOCAL_RECOGNITION_CONFIG_DIR}\")\n",
    "\n",
    "print(f\"\\n‚òÅÔ∏è  S3 STORAGE:\")\n",
    "print(f\"   ü™£ Bucket: s3://{S3_BUCKET}\")\n",
    "print(f\"   üìÑ Recognition data: {S3_RECOGNITION_DATA_PREFIX}/\")\n",
    "print(f\"   üéØ Recognition models: {S3_RECOGNITION_MODEL_PREFIX}/\")\n",
    "\n",
    "print(f\"\\nüöÄ TO START TRAINING:\")\n",
    "print(f\"   1. Ensure GPU is available: {paddle.is_compiled_with_cuda()}\")\n",
    "print(f\"   2. Upload your recognition data to S3\")\n",
    "print(f\"   3. Uncomment training code in Section 8\")\n",
    "print(f\"   4. Run: training_success = start_recognition_training(output_config_path)\")\n",
    "print(f\"   5. Monitor progress and sync checkpoints to S3\")\n",
    "\n",
    "print(f\"\\nüìñ TRAINING COMMAND:\")\n",
    "print(f\"   cd {PADDLEOCR_DIR}\")\n",
    "print(f\"   python tools/train.py -c {output_config_path}\")\n",
    "\n",
    "print(f\"\\nüìö DOCUMENTATION:\")\n",
    "print(f\"   üìã Data format: docs/data-format.md\")\n",
    "print(f\"   üîß Configuration: docs/configuration-guide.md\")\n",
    "print(f\"   üêõ Troubleshooting: docs/troubleshooting.md\")\n",
    "print(f\"   üìù Problem log: docs/problem-log.md\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  IMPORTANT NOTES:\")\n",
    "print(f\"   ‚Ä¢ This notebook is for Recognition training only\")\n",
    "print(f\"   ‚Ä¢ No text detection functionality included\")\n",
    "print(f\"   ‚Ä¢ Training requires GPU for reasonable performance\")\n",
    "print(f\"   ‚Ä¢ Check docs/problem-log.md before troubleshooting\")\n",
    "print(f\"   ‚Ä¢ Backup important models to S3 regularly\")\n",
    "\n",
    "print(f\"\\nüéØ EXPECTED OUTPUT:\")\n",
    "print(f\"   üìä Trained Recognition model (.pdparams)\")\n",
    "print(f\"   üìà Training logs and metrics\")\n",
    "print(f\"   üíæ Model checkpoints in S3\")\n",
    "print(f\"   üß™ Ready for inference and deployment\")\n",
    "\n",
    "print(f\"\\nüí° NEXT STEPS AFTER TRAINING:\")\n",
    "print(f\"   1. Download latest .pdparams from S3\")\n",
    "print(f\"   2. Test model with sample images\")\n",
    "print(f\"   3. Deploy using PaddleOCR inference API\")\n",
    "print(f\"   4. Integrate into your application\")\n",
    "\n",
    "print(f\"\\nüîó USEFUL COMMANDS:\")\n",
    "print(f\"   # Check GPU status\")\n",
    "print(f\"   nvidia-smi\")\n",
    "print(f\"   \")\n",
    "print(f\"   # Monitor training progress\")\n",
    "print(f\"   tail -f {LOCAL_RECOGNITION_MODEL_DIR}/training.log\")\n",
    "print(f\"   \")\n",
    "print(f\"   # Test recognition inference\")\n",
    "print(f\"   python tools/infer_rec.py -c config.yml -o Global.infer_img=test.jpg\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*77)\n",
    "print(f\"‚úÖ PaddleOCR Recognition Training setup completed successfully!\")\n",
    "print(f\"üöÄ Ready to train Text Recognition models on SageMaker\")\n",
    "print(f\"=\"*77)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
