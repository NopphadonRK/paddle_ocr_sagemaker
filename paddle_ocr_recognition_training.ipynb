{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4031461c",
   "metadata": {},
   "source": [
    "# PaddleOCR Text Recognition Training on Amazon SageMaker\n",
    "\n",
    "This notebook demonstrates how to train **Text Recognition models only** using PaddleOCR on Amazon SageMaker with GPU support.\n",
    "\n",
    "## Key Features:\n",
    "- **‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Text Recognition** (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° Detection)\n",
    "- ‡πÉ‡∏ä‡πâ `tools/train_rec.py` script\n",
    "- ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö annotation: `image_path\\ttext_content`\n",
    "- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö CRNN, SVTR, PP-OCRv4 architectures\n",
    "- S3 integration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data ‡πÅ‡∏•‡∏∞ model management\n",
    "\n",
    "## Requirements:\n",
    "- Amazon SageMaker Notebook Instance ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö GPU\n",
    "- PaddlePaddle GPU version\n",
    "- ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á S3 bucket ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ce87b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & GPU Check\n",
    "\n",
    "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Text Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ENVIRONMENT SETUP & INITIALIZATION =====\n",
    "# ‡∏£‡∏±‡∏ô cell ‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ cell ‡∏ô‡∏µ‡πâ‡∏£‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á\n",
    "if 'ENVIRONMENT_INITIALIZED' in globals():\n",
    "    print(\"‚ö†Ô∏è  Environment already initialized. Skipping setup...\")\n",
    "    print(f\"‚úÖ S3 bucket: {S3_BUCKET}\")\n",
    "    print(f\"‚úÖ Region: {AWS_REGION}\")\n",
    "else:\n",
    "    print(\"üîß Environment Setup for PaddleOCR Recognition Training\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python environment\n",
    "    print(f\"üìç Python version: {sys.version}\")\n",
    "    print(f\"üìç Working directory: {os.getcwd()}\")\n",
    "    \n",
    "    # 2. ‡πÇ‡∏´‡∏•‡∏î AWS configuration\n",
    "    try:\n",
    "        with open('aws-config.json', 'r') as f:\n",
    "            aws_config = json.load(f)\n",
    "        \n",
    "        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables ‡∏à‡∏≤‡∏Å config\n",
    "        credentials = aws_config['credentials']\n",
    "        aws_settings = aws_config['aws_settings']\n",
    "        \n",
    "        os.environ['AWS_ACCESS_KEY_ID'] = credentials['aws_access_key_id']\n",
    "        os.environ['AWS_SECRET_ACCESS_KEY'] = credentials['aws_secret_access_key']\n",
    "        os.environ['AWS_SESSION_TOKEN'] = credentials['aws_session_token']\n",
    "        os.environ['AWS_DEFAULT_REGION'] = aws_settings['region']\n",
    "        \n",
    "        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Global variables (‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å cell)\n",
    "        S3_BUCKET = aws_settings['s3_bucket_name']\n",
    "        AWS_REGION = aws_settings['region']\n",
    "        SAGEMAKER_REGION = aws_settings['sagemaker_region']\n",
    "        S3_DATA_PREFIX = 'recognition-data'\n",
    "        \n",
    "        print(f\"‚úÖ AWS credentials loaded\")\n",
    "        print(f\"‚úÖ S3 bucket: {S3_BUCKET}\")\n",
    "        print(f\"‚úÖ Region: {AWS_REGION}\")\n",
    "        \n",
    "        # Mark as initialized\n",
    "        ENVIRONMENT_INITIALIZED = True\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå aws-config.json not found! Please run setup first.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading AWS config: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 3. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)\n",
    "    print(\"\\nüì¶ Installing required packages...\")\n",
    "    packages_to_install = [\n",
    "        \"paddlepaddle-gpu\", \"boto3\", \"sagemaker\", \n",
    "        \"opencv-python\", \"pillow\", \"numpy\", \"PyYAML\", \"tqdm\"\n",
    "    ]\n",
    "    \n",
    "    for package in packages_to_install:\n",
    "        try:\n",
    "            __import__(package.replace('-', '_'))\n",
    "            print(f\"  ‚úÖ {package} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"  üì¶ Installing {package}...\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], check=True)\n",
    "    \n",
    "    # 4. Import ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à)\n",
    "    try:\n",
    "        import boto3\n",
    "        import sagemaker\n",
    "        import paddle\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        import yaml\n",
    "        from tqdm import tqdm\n",
    "        print(\"‚úÖ All imports successful\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Import error: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 5. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU\n",
    "    try:\n",
    "        if paddle.is_compiled_with_cuda():\n",
    "            print(\"‚úÖ PaddlePaddle GPU support available\")\n",
    "            gpu_count = paddle.device.cuda.device_count()\n",
    "            print(f\"‚úÖ Available GPUs: {gpu_count}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  PaddlePaddle CPU version detected\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not check GPU status: {e}\")\n",
    "    \n",
    "    # 6. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö AWS connection\n",
    "    try:\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"‚úÖ AWS connection successful\")\n",
    "        print(f\"   Account: {identity['Account']}\")\n",
    "        \n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö S3 access\n",
    "        s3 = boto3.client('s3')\n",
    "        s3.head_bucket(Bucket=S3_BUCKET)\n",
    "        print(f\"‚úÖ S3 bucket accessible: {S3_BUCKET}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå AWS connection failed: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(f\"\\nüéØ Environment ready for PaddleOCR Recognition training!\")\n",
    "    print(f\"üìÅ Data location: s3://{S3_BUCKET}/recognition-data/\")\n",
    "    print(f\"üèãÔ∏è Training will use: {SAGEMAKER_REGION} region\")\n",
    "    print(f\"\\n‚ö†Ô∏è  Note: Other cells will check this initialization before running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e063573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PADDLEOCR REPOSITORY SETUP =====\n",
    "# Clone ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ PaddleOCR repository\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ environment ‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß\n",
    "if 'ENVIRONMENT_INITIALIZED' not in globals():\n",
    "    print(\"‚ùå Please run Environment Setup cell first!\")\n",
    "    raise RuntimeError(\"Environment not initialized\")\n",
    "\n",
    "print(\"üì• PaddleOCR Repository Setup\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ PaddleOCR setup ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á\n",
    "PADDLEOCR_DIR = Path(\"PaddleOCR\")\n",
    "\n",
    "if PADDLEOCR_DIR.exists() and 'PADDLEOCR_READY' in globals():\n",
    "    print(\"‚úÖ PaddleOCR already set up and ready\")\n",
    "    print(f\"üìÅ Directory: {PADDLEOCR_DIR}\")\n",
    "    print(f\"‚öôÔ∏è Training tools: PaddleOCR/tools/train.py\")\n",
    "    print(f\"üìã Config files: PaddleOCR/configs/rec/\")\n",
    "else:\n",
    "    # Clone ‡∏´‡∏£‡∏∑‡∏≠ update repository\n",
    "    if PADDLEOCR_DIR.exists():\n",
    "        print(\"‚úÖ PaddleOCR directory exists, updating...\")\n",
    "        try:\n",
    "            os.chdir(\"PaddleOCR\")\n",
    "            result = subprocess.run([\"git\", \"pull\", \"origin\", \"main\"], \n",
    "                                 capture_output=True, text=True, timeout=60)\n",
    "            if result.returncode == 0:\n",
    "                print(\"‚úÖ Repository updated successfully\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Update failed: {result.stderr}\")\n",
    "            os.chdir(\"..\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not update: {e}\")\n",
    "            os.chdir(\"..\")\n",
    "    else:\n",
    "        print(\"üì• Cloning PaddleOCR repository...\")\n",
    "        try:\n",
    "            result = subprocess.run([\"git\", \"clone\", \n",
    "                                   \"https://github.com/PaddlePaddle/PaddleOCR.git\"], \n",
    "                                  capture_output=True, text=True, timeout=300)\n",
    "            if result.returncode == 0:\n",
    "                print(\"‚úÖ Repository cloned successfully\")\n",
    "            else:\n",
    "                print(f\"‚ùå Clone failed: {result.stderr}\")\n",
    "                raise RuntimeError(\"Failed to clone PaddleOCR repository\")\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"‚ùå Clone timeout - please check internet connection\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Clone error: {e}\")\n",
    "            raise\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n",
    "    if PADDLEOCR_DIR.exists():\n",
    "        important_paths = [\n",
    "            \"PaddleOCR/configs/rec\",\n",
    "            \"PaddleOCR/tools/train.py\",\n",
    "            \"PaddleOCR/ppocr\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nüìÇ Verifying important directories and files:\")\n",
    "        all_paths_exist = True\n",
    "        for path in important_paths:\n",
    "            if Path(path).exists():\n",
    "                print(f\"  ‚úÖ {path}\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {path} - NOT FOUND\")\n",
    "                all_paths_exist = False\n",
    "        \n",
    "        if all_paths_exist:\n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Recognition configs ‡∏ó‡∏µ‡πà‡∏°‡∏µ\n",
    "            rec_configs_dir = Path(\"PaddleOCR/configs/rec\")\n",
    "            rec_configs = list(rec_configs_dir.glob(\"*.yml\"))\n",
    "            print(f\"\\nüìã Available Recognition configs ({len(rec_configs)}):\")\n",
    "            for config in sorted(rec_configs)[:5]:  # ‡πÅ‡∏™‡∏î‡∏á 5 ‡∏≠‡∏±‡∏ô‡πÅ‡∏£‡∏Å\n",
    "                print(f\"  üìÑ {config.name}\")\n",
    "            if len(rec_configs) > 5:\n",
    "                print(f\"  ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(rec_configs) - 5} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "            \n",
    "            # Mark as ready\n",
    "            PADDLEOCR_READY = True\n",
    "            print(f\"\\n‚úÖ PaddleOCR repository ready!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå PaddleOCR repository incomplete!\")\n",
    "            raise RuntimeError(\"PaddleOCR repository setup failed\")\n",
    "    else:\n",
    "        print(f\"‚ùå PaddleOCR directory not found after setup!\")\n",
    "        raise RuntimeError(\"PaddleOCR repository setup failed\")\n",
    "\n",
    "print(f\"üìÅ Training tools: PaddleOCR/tools/train.py\")\n",
    "print(f\"‚öôÔ∏è Config files: PaddleOCR/configs/rec/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ee53f",
   "metadata": {},
   "source": [
    "## 2. Download Training Data from S3\n",
    "\n",
    "‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏≤‡∏Å S3 ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á images, annotations ‡πÅ‡∏•‡∏∞ character dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2227f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== S3 DATA MANAGEMENT =====\n",
    "# ‡πÉ‡∏ä‡πâ variables ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô environment setup\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ environment ‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß\n",
    "if 'ENVIRONMENT_INITIALIZED' not in globals():\n",
    "    print(\"‚ùå Please run Environment Setup cell first!\")\n",
    "    raise RuntimeError(\"Environment not initialized\")\n",
    "\n",
    "print(\"üì° S3 Data Management Setup\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á\n",
    "if 'DATA_DOWNLOADED' in globals():\n",
    "    print(\"‚úÖ Data already downloaded and ready\")\n",
    "    print(f\"üìÅ Training annotation: s3_data/annotations/train_annotation.txt\")\n",
    "    print(f\"üìÅ Validation annotation: s3_data/annotations/val_annotation.txt\")\n",
    "    print(f\"üìÅ Character dictionary: character_dict.txt\")\n",
    "else:\n",
    "    # Local paths ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    data_dirs = [\n",
    "        \"s3_data/images/train\",\n",
    "        \"s3_data/images/val\", \n",
    "        \"s3_data/annotations\",\n",
    "        \"s3_data/metadata\"\n",
    "    ]\n",
    "\n",
    "    for dir_path in data_dirs:\n",
    "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"üìÅ Created: {dir_path}\")\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    def download_s3_folder(bucket, s3_prefix, local_dir):\n",
    "        \"\"\"‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å S3\"\"\"\n",
    "        print(f\"üì• Downloading {s3_prefix} to {local_dir}...\")\n",
    "        \n",
    "        # ‡∏•‡∏¥‡∏™‡∏ï‡πå‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô S3\n",
    "        paginator = s3.get_paginator('list_objects_v2')\n",
    "        pages = paginator.paginate(Bucket=bucket, Prefix=s3_prefix)\n",
    "        \n",
    "        files_to_download = []\n",
    "        for page in pages:\n",
    "            if 'Contents' in page:\n",
    "                for obj in page['Contents']:\n",
    "                    if not obj['Key'].endswith('/'):  # ‡∏Ç‡πâ‡∏≤‡∏° directories\n",
    "                        files_to_download.append(obj['Key'])\n",
    "        \n",
    "        print(f\"üìä Found {len(files_to_download)} files to download\")\n",
    "        \n",
    "        # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå\n",
    "        if len(files_to_download) > 0:\n",
    "            progress_bar = tqdm(files_to_download, desc=\"Downloading\")\n",
    "            \n",
    "            for s3_key in progress_bar:\n",
    "                # ‡∏™‡∏£‡πâ‡∏≤‡∏á local path\n",
    "                relative_path = s3_key.replace(s3_prefix, '').lstrip('/')\n",
    "                local_path = Path(local_dir) / relative_path\n",
    "                \n",
    "                # ‡∏™‡∏£‡πâ‡∏≤‡∏á directory ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "                local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå\n",
    "                try:\n",
    "                    s3.download_file(bucket, s3_key, str(local_path))\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Failed to download {s3_key}: {e}\")\n",
    "            \n",
    "            progress_bar.close()\n",
    "            return len(files_to_download)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No files found to download\")\n",
    "            return 0\n",
    "\n",
    "    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    total_downloaded = 0\n",
    "\n",
    "    print(\"\\n1Ô∏è‚É£ Downloading annotation files...\")\n",
    "    annotation_files = [\n",
    "        f\"{S3_DATA_PREFIX}/annotations/train_annotation.txt\",\n",
    "        f\"{S3_DATA_PREFIX}/annotations/val_annotation.txt\"\n",
    "    ]\n",
    "\n",
    "    for s3_key in annotation_files:\n",
    "        local_path = f\"s3_data/{s3_key.replace(S3_DATA_PREFIX + '/', '')}\"\n",
    "        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            s3.download_file(S3_BUCKET, s3_key, local_path)\n",
    "            print(f\"  ‚úÖ {local_path}\")\n",
    "            total_downloaded += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå {s3_key}: {e}\")\n",
    "\n",
    "    print(\"\\n2Ô∏è‚É£ Downloading metadata files...\")\n",
    "    metadata_files = [\n",
    "        f\"{S3_DATA_PREFIX}/metadata/character_dict.txt\",\n",
    "        f\"{S3_DATA_PREFIX}/metadata/dataset_info.json\"\n",
    "    ]\n",
    "\n",
    "    for s3_key in metadata_files:\n",
    "        local_path = f\"s3_data/{s3_key.replace(S3_DATA_PREFIX + '/', '')}\"\n",
    "        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            s3.download_file(S3_BUCKET, s3_key, local_path)\n",
    "            print(f\"  ‚úÖ {local_path}\")\n",
    "            total_downloaded += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå {s3_key}: {e}\")\n",
    "\n",
    "    # Copy character dict ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddleOCR\n",
    "    if Path(\"s3_data/metadata/character_dict.txt\").exists():\n",
    "        import shutil\n",
    "        shutil.copy(\"s3_data/metadata/character_dict.txt\", \"character_dict.txt\")\n",
    "        print(\"‚úÖ Character dictionary copied to root directory\")\n",
    "\n",
    "    print(\"\\n3Ô∏è‚É£ Downloading training images...\")\n",
    "    train_downloaded = download_s3_folder(S3_BUCKET, f\"{S3_DATA_PREFIX}/images/train/\", \"s3_data/images/train\")\n",
    "\n",
    "    print(\"\\n4Ô∏è‚É£ Downloading validation images...\")\n",
    "    val_downloaded = download_s3_folder(S3_BUCKET, f\"{S3_DATA_PREFIX}/images/val/\", \"s3_data/images/val\")\n",
    "\n",
    "    total_downloaded += train_downloaded + val_downloaded\n",
    "\n",
    "    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î\n",
    "    print(f\"\\nüìä Download Summary:\")\n",
    "    print(f\"  üì• Total files downloaded: {total_downloaded}\")\n",
    "    print(f\"  üèãÔ∏è Training images: {train_downloaded}\")\n",
    "    print(f\"  ‚úÖ Validation images: {val_downloaded}\")\n",
    "\n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î\n",
    "    if Path(\"s3_data/annotations/train_annotation.txt\").exists():\n",
    "        with open(\"s3_data/annotations/train_annotation.txt\", 'r') as f:\n",
    "            train_lines = len(f.readlines())\n",
    "        print(f\"  üìã Training annotations: {train_lines}\")\n",
    "\n",
    "    if Path(\"s3_data/annotations/val_annotation.txt\").exists():\n",
    "        with open(\"s3_data/annotations/val_annotation.txt\", 'r') as f:\n",
    "            val_lines = len(f.readlines())\n",
    "        print(f\"  üìã Validation annotations: {val_lines}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Data download completed!\")\n",
    "    print(f\"üìÅ Local data directory: ./s3_data/\")\n",
    "    print(f\"üî§ Character dictionary: ./character_dict.txt\")\n",
    "\n",
    "    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ flag ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    DATA_DOWNLOADED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782464d1",
   "metadata": {},
   "source": [
    "## 3. Prepare Recognition Annotation Files\n",
    "\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: `image_path\\ttext_content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158484c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_recognition_annotation_file(annotation_path, num_samples=10):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå annotation ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition\n",
    "    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: image_path\\ttext_content\n",
    "    \"\"\"\n",
    "    sample_annotations = []\n",
    "    \n",
    "    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition\n",
    "    sample_texts = [\n",
    "        \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö\", \"PaddleOCR\", \"Text Recognition\", \"1234567890\",\n",
    "        \"Hello World\", \"‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö\", \"Ê∑±Â∫¶Â≠¶‰π†\", \"Machine Learning\",\n",
    "        \"Amazon SageMaker\", \"‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\"\n",
    "    ]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image_path = f\"recognition_images/word_{i:03d}.jpg\"\n",
    "        text_content = sample_texts[i % len(sample_texts)]\n",
    "        \n",
    "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Recognition: image_path\\ttext_content\n",
    "        line = f\"{image_path}\\t{text_content}\"\n",
    "        sample_annotations.append(line)\n",
    "    \n",
    "    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå\n",
    "    with open(annotation_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(sample_annotations))\n",
    "    \n",
    "    print(f\"‚úÖ Created recognition annotation file: {annotation_path}\")\n",
    "    return annotation_path\n",
    "\n",
    "# ===== ANNOTATION FILE VALIDATION =====\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå annotation ‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "if 'DATA_DOWNLOADED' not in globals():\n",
    "    print(\"‚ùå Please run S3 Data Management cell first!\")\n",
    "    raise RuntimeError(\"Data not downloaded\")\n",
    "\n",
    "print(\"üìã Recognition Annotation Validation\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def validate_recognition_annotation_format(annotation_file):\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition\n",
    "    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: image_path\\ttext_content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        print(f\"üìÑ File: {annotation_file}\")\n",
    "        print(f\"üìä Total lines: {len(lines)}\")\n",
    "        \n",
    "        valid_lines = 0\n",
    "        for line_num, line in enumerate(lines, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # ‡πÅ‡∏¢‡∏Å‡∏î‡πâ‡∏ß‡∏¢ tab\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) != 2:\n",
    "                print(f\"‚ùå Error at line {line_num}: Expected 2 parts separated by tab, got {len(parts)}\")\n",
    "                print(f\"   Line content: {repr(line)}\")\n",
    "                return False, 0\n",
    "            \n",
    "            image_path, text_content = parts\n",
    "            \n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "            if not text_content.strip():\n",
    "                print(f\"‚ùå Error at line {line_num}: Empty text content\")\n",
    "                return False, 0\n",
    "            \n",
    "            valid_lines += 1\n",
    "            \n",
    "            if line_num <= 3:  # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å\n",
    "                print(f\"   Line {line_num}: {image_path} -> {text_content}\")\n",
    "        \n",
    "        print(f\"‚úÖ Valid annotation lines: {valid_lines}\")\n",
    "        return True, valid_lines\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error validating annotation file: {e}\")\n",
    "        return False, 0\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå annotation\n",
    "train_annotation_file = \"s3_data/annotations/train_annotation.txt\"\n",
    "val_annotation_file = \"s3_data/annotations/val_annotation.txt\"\n",
    "\n",
    "print(\"üîç Validating downloaded annotation files...\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö training annotation\n",
    "if Path(train_annotation_file).exists():\n",
    "    train_valid, train_count = validate_recognition_annotation_format(train_annotation_file)\n",
    "else:\n",
    "    print(f\"‚ùå Training annotation file not found: {train_annotation_file}\")\n",
    "    train_valid, train_count = False, 0\n",
    "\n",
    "print()\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö validation annotation  \n",
    "if Path(val_annotation_file).exists():\n",
    "    val_valid, val_count = validate_recognition_annotation_format(val_annotation_file)\n",
    "else:\n",
    "    print(f\"‚ùå Validation annotation file not found: {val_annotation_file}\")\n",
    "    val_valid, val_count = False, 0\n",
    "\n",
    "if train_valid and val_valid:\n",
    "    print(f\"\\n‚úÖ All annotation files are valid!\")\n",
    "    print(f\"üìä Training samples: {train_count}\")\n",
    "    print(f\"üìä Validation samples: {val_count}\")\n",
    "    print(f\"üìä Total samples: {train_count + val_count}\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö character dictionary\n",
    "    char_dict_file = \"character_dict.txt\"\n",
    "    if Path(char_dict_file).exists():\n",
    "        with open(char_dict_file, 'r', encoding='utf-8') as f:\n",
    "            chars = f.read().strip()\n",
    "        print(f\"üî§ Character dictionary: {len(chars)} characters\")\n",
    "        print(f\"   Characters: {chars[:50]}{'...' if len(chars) > 50 else ''}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Character dictionary not found: {char_dict_file}\")\n",
    "    \n",
    "    # Set flag ‡∏ß‡πà‡∏≤ annotation files ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß\n",
    "    ANNOTATIONS_VALIDATED = True\n",
    "else:\n",
    "    print(f\"\\n‚ùå Annotation validation failed!\")\n",
    "    raise RuntimeError(\"Invalid annotation files\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå annotation ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "train_annotation_file = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"train_recognition.txt\")\n",
    "val_annotation_file = os.path.join(LOCAL_RECOGNITION_DATA_DIR, \"val_recognition.txt\")\n",
    "\n",
    "print(\"üìù Creating sample recognition annotation files...\")\n",
    "create_recognition_annotation_file(train_annotation_file, 20)\n",
    "create_recognition_annotation_file(val_annotation_file, 5)\n",
    "\n",
    "print(\"\\nüîç Validating annotation files...\")\n",
    "validate_recognition_annotation_format(train_annotation_file)\n",
    "validate_recognition_annotation_format(val_annotation_file)\n",
    "\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô PaddleOCR Recognition Model\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üöÄ Starting PaddleOCR Recognition Training\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "required_files = [\n",
    "    \"recognition_training_config.yml\",\n",
    "    \"character_dict.txt\",\n",
    "    \"s3_data/annotations/train_annotation.txt\",\n",
    "    \"s3_data/annotations/val_annotation.txt\"\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "for file_path in required_files:\n",
    "    if not Path(file_path).exists():\n",
    "        missing_files.append(file_path)\n",
    "    else:\n",
    "        print(f\"‚úÖ {file_path}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n‚ùå Missing required files:\")\n",
    "    for file_path in missing_files:\n",
    "        print(f\"  - {file_path}\")\n",
    "    print(\"Please run previous cells first!\")\n",
    "else:\n",
    "    print(f\"\\nüìã Training Configuration:\")\n",
    "    print(f\"  ‚öôÔ∏è Config: recognition_training_config.yml\")\n",
    "    print(f\"  üî§ Character dict: character_dict.txt\")\n",
    "    print(f\"  üèãÔ∏è Training data: s3_data/annotations/train_annotation.txt\")\n",
    "    print(f\"  ‚úÖ Validation data: s3_data/annotations/val_annotation.txt\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á output directory\n",
    "    output_dir = f\"./output/rec_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"  üíæ Output directory: {output_dir}\")\n",
    "    \n",
    "    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï config ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ output directory ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "    import yaml\n",
    "    with open(\"recognition_training_config.yml\", 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    config['Global']['save_model_dir'] = output_dir\n",
    "    \n",
    "    with open(\"recognition_training_config.yml\", 'w') as f:\n",
    "        yaml.safe_dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Training Command:\")\n",
    "    train_cmd = [\n",
    "        \"python\", \"PaddleOCR/tools/train.py\",\n",
    "        \"-c\", \"recognition_training_config.yml\"\n",
    "    ]\n",
    "    print(f\"  {' '.join(train_cmd)}\")\n",
    "    \n",
    "    # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô\n",
    "    print(f\"\\nüîß Training Options:\")\n",
    "    print(f\"1. üöÄ Quick Demo Training (3 epochs)\")\n",
    "    print(f\"2. üèãÔ∏è Full Production Training (10 epochs)\")\n",
    "    print(f\"3. üõ†Ô∏è Custom Training (specify options)\")\n",
    "    print(f\"4. üìã Just show command (don't run)\")\n",
    "    \n",
    "    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô epochs ‡πÄ‡∏õ‡πá‡∏ô 3\n",
    "    choice = input(\"\\nSelect training option (1-4): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        print(f\"\\nüöÄ Starting Quick Demo Training (3 epochs)...\")\n",
    "        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo\n",
    "        config['Global']['epoch_num'] = 3\n",
    "        config['Global']['save_epoch_step'] = 1\n",
    "        with open(\"recognition_training_config.yml\", 'w') as f:\n",
    "            yaml.safe_dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "        \n",
    "        # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "        print(f\"‚è∞ Training started at: {datetime.now()}\")\n",
    "        try:\n",
    "            process = subprocess.Popen(\n",
    "                train_cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                universal_newlines=True,\n",
    "                bufsize=1\n",
    "            )\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• output ‡πÅ‡∏ö‡∏ö real-time\n",
    "            for line in process.stdout:\n",
    "                print(line.strip())\n",
    "            \n",
    "            process.wait()\n",
    "            \n",
    "            if process.returncode == 0:\n",
    "                print(f\"\\nüéâ Training completed successfully!\")\n",
    "                print(f\"üìÅ Model saved in: {output_dir}\")\n",
    "            else:\n",
    "                print(f\"\\n‚ùå Training failed with return code: {process.returncode}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Training error: {e}\")\n",
    "    \n",
    "    elif choice == \"2\":\n",
    "        print(f\"\\nüèãÔ∏è Starting Full Production Training (10 epochs)...\")\n",
    "        print(f\"‚è∞ Training started at: {datetime.now()}\")\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(train_cmd, capture_output=True, text=True)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"üéâ Training completed successfully!\")\n",
    "                print(f\"üìÅ Model saved in: {output_dir}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Training failed:\")\n",
    "                print(result.stderr)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training error: {e}\")\n",
    "    \n",
    "    elif choice == \"3\":\n",
    "        epochs = input(\"Enter number of epochs (default 10): \").strip() or \"10\"\n",
    "        config['Global']['epoch_num'] = int(epochs)\n",
    "        \n",
    "        with open(\"recognition_training_config.yml\", 'w') as f:\n",
    "            yaml.safe_dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "        \n",
    "        print(f\"\\nüõ†Ô∏è Starting Custom Training ({epochs} epochs)...\")\n",
    "        print(f\"‚è∞ Training started at: {datetime.now()}\")\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(train_cmd, capture_output=True, text=True)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"üéâ Training completed successfully!\")\n",
    "                print(f\"üìÅ Model saved in: {output_dir}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Training failed:\")\n",
    "                print(result.stderr)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training error: {e}\")\n",
    "    \n",
    "    elif choice == \"4\":\n",
    "        print(f\"\\nüìã Training Command to run manually:\")\n",
    "        print(f\"cd {os.getcwd()}\")\n",
    "        print(f\"{' '.join(train_cmd)}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Invalid choice. Please run this cell again.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training setup completed!\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Training Configuration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddleOCR Recognition\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def create_recognition_config():\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á configuration file ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition training\"\"\"\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î base config ‡∏à‡∏≤‡∏Å PaddleOCR\n",
    "    base_config_path = \"configs/rec/rec_mv3_none_bilstm_ctc.yml\"\n",
    "    \n",
    "    if not Path(base_config_path).exists():\n",
    "        print(f\"‚ùå Base config not found: {base_config_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìã Loading base config: {base_config_path}\")\n",
    "    \n",
    "    with open(base_config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï configuration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤\n",
    "    LOCAL_DATA_DIR = PROJECT_CONFIG['LOCAL_DATA_DIR']\n",
    "    \n",
    "    # Global settings\n",
    "    config['Global'].update({\n",
    "        'epoch_num': PROJECT_CONFIG['TRAINING_CONFIG']['epochs'],\n",
    "        'log_smooth_window': 20,\n",
    "        'print_batch_step': 10,\n",
    "        'save_model_dir': './output/rec_mv3_ctc',\n",
    "        'save_epoch_step': 10,\n",
    "        'eval_batch_step': [0, 500],\n",
    "        'cal_metric_during_training': True,\n",
    "        'pretrained_model': None,\n",
    "        'checkpoints': None,\n",
    "        'use_visualdl': True,\n",
    "        'infer_img': f\"{LOCAL_DATA_DIR}/images/val\",\n",
    "        'character_dict_path': f\"{LOCAL_DATA_DIR}/metadata/character_dict.txt\",\n",
    "        'character_type': 'ch',\n",
    "        'max_text_length': PROJECT_CONFIG['TRAINING_CONFIG']['max_text_length'],\n",
    "        'use_space_char': False,\n",
    "        'save_res_path': './output/rec/predicts_rec.txt'\n",
    "    })\n",
    "    \n",
    "    # Architecture settings\n",
    "    config['Architecture'] = {\n",
    "        'model_type': 'rec',\n",
    "        'algorithm': 'CRNN',\n",
    "        'Transform': None,\n",
    "        'Backbone': {\n",
    "            'name': 'MobileNetV3',\n",
    "            'scale': 0.5,\n",
    "            'model_name': 'small'\n",
    "        },\n",
    "        'Neck': {\n",
    "            'name': 'SequenceEncoder',\n",
    "            'encoder_type': 'rnn',\n",
    "            'hidden_size': 48\n",
    "        },\n",
    "        'Head': {\n",
    "            'name': 'CTCHead',\n",
    "            'fc_decay': 0.00001\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Loss settings\n",
    "    config['Loss'] = {\n",
    "        'name': 'CTCLoss'\n",
    "    }\n",
    "    \n",
    "    # Optimizer settings\n",
    "    config['Optimizer'] = {\n",
    "        'name': 'Adam',\n",
    "        'beta1': 0.9,\n",
    "        'beta2': 0.999,\n",
    "        'lr': {\n",
    "            'name': 'Piecewise',\n",
    "            'decay_epochs': [10, 20],\n",
    "            'values': [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "        'regularizer': {\n",
    "            'name': 'L2',\n",
    "            'factor': 0.00001\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # PostProcess settings\n",
    "    config['PostProcess'] = {\n",
    "        'name': 'CTCLabelDecode'\n",
    "    }\n",
    "    \n",
    "    # Metric settings\n",
    "    config['Metric'] = {\n",
    "        'name': 'RecMetric',\n",
    "        'main_indicator': 'acc'\n",
    "    }\n",
    "    \n",
    "    # Training dataset\n",
    "    config['Train'] = {\n",
    "        'dataset': {\n",
    "            'name': 'SimpleDataSet',\n",
    "            'data_dir': f\"{LOCAL_DATA_DIR}/images/train\",\n",
    "            'label_file_list': [f\"{LOCAL_DATA_DIR}/annotations/train_annotation.txt\"]\n",
    "        },\n",
    "        'loader': {\n",
    "            'shuffle': True,\n",
    "            'batch_size_per_card': PROJECT_CONFIG['TRAINING_CONFIG']['batch_size'],\n",
    "            'drop_last': True,\n",
    "            'num_workers': 4,\n",
    "            'use_shared_memory': False\n",
    "        },\n",
    "        'transforms': [\n",
    "            {'DecodeImage': {'img_mode': 'BGR', 'channel_first': False}},\n",
    "            {'CTCLabelEncode': None},\n",
    "            {'RecResizeImg': {'image_shape': [3, 32, 320]}},\n",
    "            {'KeepKeys': {'keep_keys': ['image', 'label', 'length']}}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Evaluation dataset\n",
    "    config['Eval'] = {\n",
    "        'dataset': {\n",
    "            'name': 'SimpleDataSet',\n",
    "            'data_dir': f\"{LOCAL_DATA_DIR}/images/val\",\n",
    "            'label_file_list': [f\"{LOCAL_DATA_DIR}/annotations/val_annotation.txt\"]\n",
    "        },\n",
    "        'loader': {\n",
    "            'shuffle': False,\n",
    "            'drop_last': False,\n",
    "            'batch_size_per_card': PROJECT_CONFIG['TRAINING_CONFIG']['batch_size'],\n",
    "            'num_workers': 4,\n",
    "            'use_shared_memory': False\n",
    "        },\n",
    "        'transforms': [\n",
    "            {'DecodeImage': {'img_mode': 'BGR', 'channel_first': False}},\n",
    "            {'CTCLabelEncode': None},\n",
    "            {'RecResizeImg': {'image_shape': [3, 32, 320]}},\n",
    "            {'KeepKeys': {'keep_keys': ['image', 'label', 'length']}}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "print(\"‚öôÔ∏è  Creating Training Configuration...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á config\n",
    "config = create_recognition_config()\n",
    "\n",
    "if config is None:\n",
    "    raise Exception(\"Failed to create training configuration\")\n",
    "\n",
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å config file\n",
    "config_save_path = \"train_recognition_config.yml\"\n",
    "with open(config_save_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "print(f\"‚úÖ Configuration saved: {config_save_path}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ configuration\n",
    "print(f\"\\nüìã Training Configuration Summary:\")\n",
    "print(f\"   üìÅ Output dir: {config['Global']['save_model_dir']}\")\n",
    "print(f\"   üîÑ Epochs: {config['Global']['epoch_num']}\")\n",
    "print(f\"   üì¶ Batch size: {config['Train']['loader']['batch_size_per_card']}\")\n",
    "print(f\"   üéØ Max text length: {config['Global']['max_text_length']}\")\n",
    "print(f\"   üìä Architecture: {config['Architecture']['algorithm']}\")\n",
    "print(f\"   üî§ Character dict: {config['Global']['character_dict_path']}\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "print(f\"\\nüîç Verifying required files...\")\n",
    "required_files = [\n",
    "    config['Global']['character_dict_path'],\n",
    "    config['Train']['dataset']['label_file_list'][0],\n",
    "    config['Eval']['dataset']['label_file_list'][0]\n",
    "]\n",
    "\n",
    "all_exist = True\n",
    "for file_path in required_files:\n",
    "    if Path(file_path).exists():\n",
    "        print(f\"‚úÖ {file_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file_path} - Missing!\")\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(f\"\\nüéâ Training configuration ready!\")\n",
    "    print(f\"üìù Config file: {Path(config_save_path).absolute()}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Some required files are missing!\")\n",
    "    print(\"Please check data download step\")\n",
    "\n",
    "# ‡πÄ‡∏Å‡πá‡∏ö config path ‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ\n",
    "TRAINING_CONFIG_PATH = config_save_path\n",
    "print(f\"\\nüí° Use this config for training: {TRAINING_CONFIG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e597f1",
   "metadata": {},
   "source": [
    "## 4. Create Training Configuration\n",
    "\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á configuration file ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô PaddleOCR Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea80f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRAINING CONFIGURATION CREATION =====\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á configuration file ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô PaddleOCR Recognition\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ annotation files ‡∏ñ‡∏π‡∏Å validate ‡πÅ‡∏•‡πâ‡∏ß\n",
    "if 'ANNOTATIONS_VALIDATED' not in globals():\n",
    "    print(\"‚ùå Please run Annotation Validation cell first!\")\n",
    "    raise RuntimeError(\"Annotations not validated\")\n",
    "\n",
    "print(\"‚öôÔ∏è Creating PaddleOCR Recognition Training Configuration\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def create_recognition_config():\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á configuration file ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition training\"\"\"\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î base config ‡∏à‡∏≤‡∏Å PaddleOCR\n",
    "    base_config_path = \"PaddleOCR/configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml\"\n",
    "    \n",
    "    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ config ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ\n",
    "    if not Path(base_config_path).exists():\n",
    "        base_config_path = \"PaddleOCR/configs/rec/rec_mv3_none_bilstm_ctc.yml\"\n",
    "    \n",
    "    if not Path(base_config_path).exists():\n",
    "        print(f\"‚ùå Base config not found: {base_config_path}\")\n",
    "        print(\"Available configs:\")\n",
    "        config_dir = Path(\"PaddleOCR/configs/rec\")\n",
    "        if config_dir.exists():\n",
    "            for config_file in config_dir.glob(\"*.yml\"):\n",
    "                print(f\"  üìÑ {config_file}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìã Loading base config: {base_config_path}\")\n",
    "    \n",
    "    with open(base_config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï configuration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤\n",
    "    \n",
    "    # Global settings\n",
    "    config['Global'].update({\n",
    "        'epoch_num': 10,  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epochs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "        'log_smooth_window': 20,\n",
    "        'print_batch_step': 10,\n",
    "        'save_model_dir': './output/rec_training',\n",
    "        'save_epoch_step': 5,\n",
    "        'eval_batch_step': [0, 500],\n",
    "        'cal_metric_during_training': True,\n",
    "        'pretrained_model': None,\n",
    "        'checkpoints': None,\n",
    "        'use_visualdl': True,\n",
    "        'character_dict_path': 'character_dict.txt',\n",
    "        'character_type': 'en',  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 0-9\n",
    "        'max_text_length': 10,   # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "        'use_space_char': False,\n",
    "        'save_res_path': './output/rec/predicts_rec.txt'\n",
    "    })\n",
    "    \n",
    "    # Architecture settings (‡πÉ‡∏ä‡πâ CRNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition)\n",
    "    config['Architecture'] = {\n",
    "        'model_type': 'rec',\n",
    "        'algorithm': 'CRNN',\n",
    "        'Transform': None,\n",
    "        'Backbone': {\n",
    "            'name': 'MobileNetV3',\n",
    "            'scale': 0.5,\n",
    "            'model_name': 'small'\n",
    "        },\n",
    "        'Neck': {\n",
    "            'name': 'SequenceEncoder',\n",
    "            'encoder_type': 'rnn',\n",
    "            'hidden_size': 48\n",
    "        },\n",
    "        'Head': {\n",
    "            'name': 'CTCHead',\n",
    "            'fc_decay': 0.00001\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Loss settings\n",
    "    config['Loss'] = {\n",
    "        'name': 'CTCLoss'\n",
    "    }\n",
    "    \n",
    "    # Optimizer settings\n",
    "    config['Optimizer'] = {\n",
    "        'name': 'Adam',\n",
    "        'beta1': 0.9,\n",
    "        'beta2': 0.999,\n",
    "        'lr': {\n",
    "            'name': 'Piecewise',\n",
    "            'decay_epochs': [5, 8],\n",
    "            'values': [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "        'regularizer': {\n",
    "            'name': 'L2',\n",
    "            'factor': 0.00001\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # PostProcess settings\n",
    "    config['PostProcess'] = {\n",
    "        'name': 'CTCLabelDecode'\n",
    "    }\n",
    "    \n",
    "    # Metric settings\n",
    "    config['Metric'] = {\n",
    "        'name': 'RecMetric',\n",
    "        'main_indicator': 'acc'\n",
    "    }\n",
    "    \n",
    "    # Training dataset\n",
    "    config['Train'] = {\n",
    "        'dataset': {\n",
    "            'name': 'SimpleDataSet',\n",
    "            'data_dir': 's3_data/images/train',\n",
    "            'label_file_list': ['s3_data/annotations/train_annotation.txt']\n",
    "        },\n",
    "        'loader': {\n",
    "            'shuffle': True,\n",
    "            'batch_size_per_card': 8,  # batch size ‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo\n",
    "            'drop_last': True,\n",
    "            'num_workers': 2,\n",
    "            'use_shared_memory': False\n",
    "        },\n",
    "        'transforms': [\n",
    "            {'DecodeImage': {'img_mode': 'BGR', 'channel_first': False}},\n",
    "            {'CTCLabelEncode': None},\n",
    "            {'RecResizeImg': {'image_shape': [3, 32, 320]}},\n",
    "            {'KeepKeys': {'keep_keys': ['image', 'label', 'length']}}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Evaluation dataset\n",
    "    config['Eval'] = {\n",
    "        'dataset': {\n",
    "            'name': 'SimpleDataSet',\n",
    "            'data_dir': 's3_data/images/val',\n",
    "            'label_file_list': ['s3_data/annotations/val_annotation.txt']\n",
    "        },\n",
    "        'loader': {\n",
    "            'shuffle': False,\n",
    "            'drop_last': False,\n",
    "            'batch_size_per_card': 8,\n",
    "            'num_workers': 2,\n",
    "            'use_shared_memory': False\n",
    "        },\n",
    "        'transforms': [\n",
    "            {'DecodeImage': {'img_mode': 'BGR', 'channel_first': False}},\n",
    "            {'CTCLabelEncode': None},\n",
    "            {'RecResizeImg': {'image_shape': [3, 32, 320]}},\n",
    "            {'KeepKeys': {'keep_keys': ['image', 'label', 'length']}}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á config\n",
    "config = create_recognition_config()\n",
    "\n",
    "if config is None:\n",
    "    raise Exception(\"Failed to create training configuration\")\n",
    "\n",
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å config file\n",
    "config_save_path = \"recognition_training_config.yml\"\n",
    "with open(config_save_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "print(f\"‚úÖ Configuration saved: {config_save_path}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ configuration\n",
    "print(f\"\\nüìã Training Configuration Summary:\")\n",
    "print(f\"   üìÅ Output dir: {config['Global']['save_model_dir']}\")\n",
    "print(f\"   üîÑ Epochs: {config['Global']['epoch_num']}\")\n",
    "print(f\"   üì¶ Batch size: {config['Train']['loader']['batch_size_per_card']}\")\n",
    "print(f\"   üéØ Max text length: {config['Global']['max_text_length']}\")\n",
    "print(f\"   üìä Architecture: {config['Architecture']['algorithm']}\")\n",
    "print(f\"   üî§ Character dict: {config['Global']['character_dict_path']}\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "print(f\"\\nüîç Verifying required files...\")\n",
    "required_files = [\n",
    "    config['Global']['character_dict_path'],\n",
    "    config['Train']['dataset']['label_file_list'][0],\n",
    "    config['Eval']['dataset']['label_file_list'][0]\n",
    "]\n",
    "\n",
    "all_exist = True\n",
    "for file_path in required_files:\n",
    "    if Path(file_path).exists():\n",
    "        print(f\"‚úÖ {file_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file_path} - Missing!\")\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(f\"\\nüéâ Training configuration ready!\")\n",
    "    print(f\"üìù Config file: {Path(config_save_path).absolute()}\")\n",
    "    \n",
    "    # ‡πÄ‡∏Å‡πá‡∏ö config path ‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ\n",
    "    TRAINING_CONFIG_PATH = config_save_path\n",
    "    CONFIG_CREATED = True\n",
    "else:\n",
    "    print(f\"\\n‚ùå Some required files are missing!\")\n",
    "    print(\"Please check data download step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b265ba",
   "metadata": {},
   "source": [
    "## 5. Start PaddleOCR Recognition Training\n",
    "\n",
    "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Text Recognition model ‡∏î‡πâ‡∏ß‡∏¢ PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642af0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRAINING EXECUTION =====\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô PaddleOCR Recognition Model\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ config ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß\n",
    "if 'CONFIG_CREATED' not in globals():\n",
    "    print(\"‚ùå Please run Training Configuration Creation cell first!\")\n",
    "    raise RuntimeError(\"Training config not created\")\n",
    "\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üöÄ PaddleOCR Recognition Training Execution\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "required_files = [\n",
    "    \"recognition_training_config.yml\",\n",
    "    \"character_dict.txt\",\n",
    "    \"s3_data/annotations/train_annotation.txt\",\n",
    "    \"s3_data/annotations/val_annotation.txt\"\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "for file_path in required_files:\n",
    "    if not Path(file_path).exists():\n",
    "        missing_files.append(file_path)\n",
    "    else:\n",
    "        print(f\"‚úÖ {file_path}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n‚ùå Missing required files:\")\n",
    "    for file_path in missing_files:\n",
    "        print(f\"  - {file_path}\")\n",
    "    print(\"Please run previous cells first!\")\n",
    "    raise RuntimeError(\"Missing required files\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á output directory\n",
    "output_dir = f\"./output/rec_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üíæ Output directory: {output_dir}\")\n",
    "\n",
    "# ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï config ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ output directory ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "with open(\"recognition_training_config.yml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['Global']['save_model_dir'] = output_dir\n",
    "\n",
    "with open(\"recognition_training_config.yml\", 'w') as f:\n",
    "    yaml.safe_dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(f\"üìã Training Configuration:\")\n",
    "print(f\"  ‚öôÔ∏è Config: recognition_training_config.yml\")\n",
    "print(f\"  üî§ Character dict: character_dict.txt\")\n",
    "print(f\"  üèãÔ∏è Training data: s3_data/annotations/train_annotation.txt\")\n",
    "print(f\"  ‚úÖ Validation data: s3_data/annotations/val_annotation.txt\")\n",
    "print(f\"  üíæ Output directory: {output_dir}\")\n",
    "\n",
    "print(f\"\\nüéØ Training Command:\")\n",
    "train_cmd = [\n",
    "    \"python\", \"PaddleOCR/tools/train.py\",\n",
    "    \"-c\", \"recognition_training_config.yml\"\n",
    "]\n",
    "print(f\"  {' '.join(train_cmd)}\")\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô\n",
    "print(f\"\\nüîß Training Options:\")\n",
    "print(f\"1. üöÄ Quick Demo Training (3 epochs)\")\n",
    "print(f\"2. üèãÔ∏è Full Production Training (10 epochs)\")\n",
    "print(f\"3. üõ†Ô∏è Custom Training (specify options)\")\n",
    "print(f\"4. üìã Just show command (don't run)\")\n",
    "\n",
    "# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô epochs ‡πÄ‡∏õ‡πá‡∏ô 3\n",
    "choice = input(\"\\nSelect training option (1-4): \").strip()\n",
    "\n",
    "if choice == \"1\":\n",
    "    print(f\"\\nüöÄ Starting Quick Demo Training (3 epochs)...\")\n",
    "    # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo\n",
    "    config['Global']['epoch_num'] = 3\n",
    "    config['Global']['save_epoch_step'] = 1\n",
    "    with open(\"recognition_training_config.yml\", 'w') as f:\n",
    "        yaml.safe_dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "    print(f\"‚è∞ Training started at: {datetime.now()}\")\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            train_cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            universal_newlines=True,\n",
    "            bufsize=1\n",
    "        )\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• output ‡πÅ‡∏ö‡∏ö real-time\n",
    "        for line in process.stdout:\n",
    "            print(line.strip())\n",
    "        \n",
    "        process.wait()\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "            print(f\"\\nüéâ Training completed successfully!\")\n",
    "            print(f\"üìÅ Model saved in: {output_dir}\")\n",
    "            # Set flag ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠\n",
    "            TRAINING_COMPLETED = True\n",
    "            LATEST_MODEL_DIR = output_dir\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Training failed with return code: {process.returncode}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Training error: {e}\")\n",
    "\n",
    "elif choice == \"2\":\n",
    "    print(f\"\\nüèãÔ∏è Starting Full Production Training (10 epochs)...\")\n",
    "    print(f\"‚è∞ Training started at: {datetime.now()}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(train_cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"üéâ Training completed successfully!\")\n",
    "            print(f\"üìÅ Model saved in: {output_dir}\")\n",
    "            TRAINING_COMPLETED = True\n",
    "            LATEST_MODEL_DIR = output_dir\n",
    "        else:\n",
    "            print(f\"‚ùå Training failed:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training error: {e}\")\n",
    "\n",
    "elif choice == \"3\":\n",
    "    epochs = input(\"Enter number of epochs (default 10): \").strip() or \"10\"\n",
    "    config['Global']['epoch_num'] = int(epochs)\n",
    "    \n",
    "    with open(\"recognition_training_config.yml\", 'w') as f:\n",
    "        yaml.safe_dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    print(f\"\\nüõ†Ô∏è Starting Custom Training ({epochs} epochs)...\")\n",
    "    print(f\"‚è∞ Training started at: {datetime.now()}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(train_cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"üéâ Training completed successfully!\")\n",
    "            print(f\"üìÅ Model saved in: {output_dir}\")\n",
    "            TRAINING_COMPLETED = True\n",
    "            LATEST_MODEL_DIR = output_dir\n",
    "        else:\n",
    "            print(f\"‚ùå Training failed:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training error: {e}\")\n",
    "\n",
    "elif choice == \"4\":\n",
    "    print(f\"\\nüìã Training Command to run manually:\")\n",
    "    print(f\"cd {os.getcwd()}\")\n",
    "    print(f\"{' '.join(train_cmd)}\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Invalid choice. Please run this cell again.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training execution completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebbdf2",
   "metadata": {},
   "source": [
    "## 6. Test Trained Model\n",
    "\n",
    "‡∏ó‡∏î‡∏™‡∏≠‡∏ö Recognition model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏±‡∏ö sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MODEL TESTING =====\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Recognition model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß\n",
    "if 'TRAINING_COMPLETED' not in globals():\n",
    "    print(\"‚ùå Please run Training Execution cell first!\")\n",
    "    print(\"üìã You can also manually set model path if you have a trained model:\")\n",
    "    print(\"   LATEST_MODEL_DIR = './output/your_model_directory'\")\n",
    "    print(\"   TRAINING_COMPLETED = True\")\n",
    "    # Uncomment line below and set correct path if you have a trained model\n",
    "    # LATEST_MODEL_DIR = './output/rec_training_20250101_120000'\n",
    "    # TRAINING_COMPLETED = True\n",
    "\n",
    "if 'TRAINING_COMPLETED' in globals() and 'LATEST_MODEL_DIR' in globals():\n",
    "    print(\"üî¨ Testing Trained Recognition Model\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö model directory\n",
    "    model_dir = Path(LATEST_MODEL_DIR)\n",
    "    if not model_dir.exists():\n",
    "        print(f\"‚ùå Model directory not found: {model_dir}\")\n",
    "    else:\n",
    "        print(f\"üìÅ Model directory: {model_dir}\")\n",
    "        \n",
    "        # ‡∏´‡∏≤ latest checkpoint\n",
    "        checkpoint_files = list(model_dir.glob(\"latest.pdparams\"))\n",
    "        if not checkpoint_files:\n",
    "            checkpoint_files = list(model_dir.glob(\"*.pdparams\"))\n",
    "        \n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = checkpoint_files[0]\n",
    "            print(f\"üìÑ Using checkpoint: {latest_checkpoint}\")\n",
    "            \n",
    "            # ‡∏™‡∏£‡πâ‡∏≤‡∏á inference script\n",
    "            inference_cmd = [\n",
    "                \"python\", \"PaddleOCR/tools/infer_rec.py\",\n",
    "                \"-c\", \"recognition_training_config.yml\",\n",
    "                \"-o\", f\"Global.pretrained_model={latest_checkpoint.parent}/{latest_checkpoint.stem}\",\n",
    "                \"-o\", \"Global.infer_img=s3_data/images/val/\"\n",
    "            ]\n",
    "            \n",
    "            print(f\"\\nüéØ Inference Command:\")\n",
    "            print(f\"  {' '.join(inference_cmd)}\")\n",
    "            \n",
    "            # ‡∏£‡∏±‡∏ô inference (optional - ‡πÄ‡∏û‡∏¥‡πà‡∏° UI ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)\n",
    "            run_inference = input(\"\\nDo you want to run inference now? (y/n): \").strip().lower()\n",
    "            \n",
    "            if run_inference == 'y':\n",
    "                print(f\"\\nüöÄ Running inference...\")\n",
    "                try:\n",
    "                    result = subprocess.run(inference_cmd, capture_output=True, text=True, timeout=120)\n",
    "                    \n",
    "                    if result.returncode == 0:\n",
    "                        print(f\"‚úÖ Inference completed successfully!\")\n",
    "                        print(\"\\nOutput:\")\n",
    "                        print(result.stdout)\n",
    "                    else:\n",
    "                        print(f\"‚ùå Inference failed:\")\n",
    "                        print(result.stderr)\n",
    "                        \n",
    "                except subprocess.TimeoutExpired:\n",
    "                    print(\"‚è∞ Inference timeout - please try with fewer images\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Inference error: {e}\")\n",
    "            else:\n",
    "                print(\"üìã You can run inference manually with the command above\")\n",
    "        else:\n",
    "            print(f\"‚ùå No checkpoint files found in {model_dir}\")\n",
    "            print(\"Available files:\")\n",
    "            for file in model_dir.iterdir():\n",
    "                print(f\"  üìÑ {file.name}\")\n",
    "\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ\n",
    "    print(f\"\\nüìä Training Summary:\")\n",
    "    print(f\"  üìÅ Model saved in: {LATEST_MODEL_DIR}\")\n",
    "    print(f\"  ‚öôÔ∏è Config file: recognition_training_config.yml\")\n",
    "    print(f\"  üî§ Character dict: character_dict.txt\")\n",
    "    print(f\"  üíæ S3 location: s3://{S3_BUCKET}/recognition-data/\")\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö upload ‡∏Å‡∏•‡∏±‡∏ö S3 (optional)\n",
    "    upload_model = input(\"\\nDo you want to upload trained model to S3? (y/n): \").strip().lower()\n",
    "    \n",
    "    if upload_model == 'y':\n",
    "        print(f\"\\nüì§ Uploading model to S3...\")\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        try:\n",
    "            # Upload trained model files\n",
    "            for file_path in model_dir.glob(\"*\"):\n",
    "                if file_path.is_file():\n",
    "                    s3_key = f\"recognition-models/{model_dir.name}/{file_path.name}\"\n",
    "                    s3.upload_file(str(file_path), S3_BUCKET, s3_key)\n",
    "                    print(f\"  ‚úÖ Uploaded: {s3_key}\")\n",
    "            \n",
    "            print(f\"üéâ Model uploaded to S3 successfully!\")\n",
    "            print(f\"üìç S3 location: s3://{S3_BUCKET}/recognition-models/{model_dir.name}/\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Upload failed: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Model testing and management completed!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Please run training first or manually set model path above\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
