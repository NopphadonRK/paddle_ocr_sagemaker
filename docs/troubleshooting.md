# ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Troubleshooting Guide)

## üö® ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç

### 1. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

#### ‚ùå PaddlePaddle GPU ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: `pip install paddlepaddle-gpu` ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA version
nvidia-smi

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏≤‡∏° CUDA version
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CUDA 11.8
pip install paddlepaddle-gpu==2.5.2 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CUDA 11.7
pip install paddlepaddle-gpu==2.5.2 -f https://www.paddlepaddle.org.cn/whl/cu117/

# ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ conda
conda install paddlepaddle-gpu==2.5.2 cudatoolkit=11.8 -c paddle
```

#### ‚ùå OpenCV import error
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: `ImportError: libGL.so.1: cannot open shared object file`
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á system dependencies
apt-get update
apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ opencv-python-headless
pip uninstall opencv-python
pip install opencv-python-headless
```

### 2. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ GPU ‡πÅ‡∏•‡∏∞ CUDA

#### ‚ùå GPU ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: `paddle.is_compiled_with_cuda()` ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ `False`
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA installation
import subprocess
result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
print(result.stdout)

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA driver
result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
print(result.stdout)

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PaddlePaddle ‡πÉ‡∏´‡∏°‡πà
pip uninstall paddlepaddle-gpu
pip install paddlepaddle-gpu==2.5.2 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html
```

#### ‚ùå CUDA out of memory
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: `RuntimeError: (OutOfMemory) Out of memory error on GPU`
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏•‡∏î batch size
config['Train']['loader']['batch_size_per_card'] = 4

# ‡∏•‡∏î image size
config['Train']['dataset']['transforms']['EastRandomCropData']['size'] = [640, 640]

# ‡πÉ‡∏ä‡πâ gradient accumulation
config['Global']['grad_clip'] = {'type': 'ClipGradByNorm', 'clip_norm': 5.0}
```

### 3. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Annotation

#### ‚ùå Annotation format ‡∏ú‡∏¥‡∏î
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: Training ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏´‡∏£‡∏∑‡∏≠ error ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á data loading
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå
def debug_annotation_file(annotation_file):
    with open(annotation_file, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 5:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å
                break
            
            print(f"Line {i+1}: {repr(line)}")
            
            try:
                parts = line.strip().split('\t')
                print(f"  Parts count: {len(parts)}")
                
                if len(parts) == 2:
                    image_path, annotation_json = parts
                    annotations = json.loads(annotation_json)
                    print(f"  Image: {image_path}")
                    print(f"  Annotations count: {len(annotations)}")
                    
                    for j, ann in enumerate(annotations):
                        print(f"    Annotation {j}: {ann}")
                        
            except Exception as e:
                print(f"  Error: {e}")
```

#### ‚ùå ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: `FileNotFoundError` ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á training
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
def check_image_paths(annotation_file, image_base_dir):
    missing_images = []
    
    with open(annotation_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                image_path = line.strip().split('\t')[0]
                full_path = os.path.join(image_base_dir, image_path)
                
                if not os.path.exists(full_path):
                    missing_images.append((line_num, image_path, full_path))
                    
            except:
                continue
    
    if missing_images:
        print(f"Found {len(missing_images)} missing images:")
        for line_num, rel_path, full_path in missing_images[:10]:
            print(f"  Line {line_num}: {rel_path} -> {full_path}")
    else:
        print("All images found!")
```

### 4. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô

#### ‚ùå Training ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: Script ‡∏£‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ log ‡∏´‡∏£‡∏∑‡∏≠ progress
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```bash
# ‡πÄ‡∏û‡∏¥‡πà‡∏° verbose logging
export GLOG_v=3
export GLOG_logtostderr=1

# ‡∏£‡∏±‡∏ô training ‡∏î‡πâ‡∏ß‡∏¢ Python -u ‡πÄ‡∏û‡∏∑‡πà‡∏≠ unbuffered output
python -u tools/train.py -c configs/your_config.yml

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö config file
python -c "
import yaml
with open('configs/your_config.yml', 'r') as f:
    config = yaml.safe_load(f)
print(yaml.dump(config, default_flow_style=False))
"
```

#### ‚ùå Loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: Training loss ‡∏ï‡∏¥‡∏î‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏•‡∏î learning rate
config['Optimizer']['lr']['learning_rate'] = 0.0001

# ‡πÄ‡∏û‡∏¥‡πà‡∏° warmup epochs
config['Optimizer']['lr']['warmup_epoch'] = 5

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö data augmentation
# ‡∏•‡∏≠‡∏á‡∏õ‡∏¥‡∏î augmentation ‡∏ó‡∏µ‡πà‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
config['Train']['dataset']['transforms'] = [
    {'DecodeImage': {'img_mode': 'BGR', 'channel_first': False}},
    {'DetLabelEncode': {}},
    # ‡∏•‡∏ö IaaAugment ‡∏≠‡∏≠‡∏Å‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
    {'NormalizeImage': {'scale': '1./255.', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'order': 'hwc'}},
    {'ToCHWImage': {}},
    {'KeepKeys': {'keep_keys': ['image', 'threshold_map', 'threshold_mask', 'shrink_map', 'shrink_mask']}}
]
```

### 5. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ S3 ‡πÅ‡∏•‡∏∞ AWS

#### ‚ùå S3 access denied
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: `botocore.exceptions.ClientError: An error occurred (AccessDenied)`
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö AWS credentials
import boto3
session = boto3.Session()
credentials = session.get_credentials()
print(f"Access Key: {credentials.access_key}")
print(f"Secret Key: {credentials.secret_key[:10]}...")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö IAM permissions
s3 = boto3.client('s3')
try:
    s3.list_buckets()
    print("S3 access OK")
except Exception as e:
    print(f"S3 access failed: {e}")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö bucket policy
try:
    response = s3.get_bucket_policy(Bucket='your-bucket-name')
    print("Bucket policy:", response['Policy'])
except Exception as e:
    print(f"Cannot get bucket policy: {e}")
```

#### ‚ùå S3 upload/download ‡∏ä‡πâ‡∏≤
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: ‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡πÇ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡πÉ‡∏ä‡πâ multipart upload
import boto3
from boto3.s3.transfer import TransferConfig

config = TransferConfig(
    multipart_threshold=1024 * 25,  # 25MB
    max_concurrency=10,
    multipart_chunksize=1024 * 25,
    use_threads=True
)

s3_client = boto3.client('s3')
s3_client.upload_file(
    'large_file.zip', 
    'your-bucket', 
    'key', 
    Config=config
)

# ‡πÉ‡∏ä‡πâ S3 Transfer Acceleration
s3_client = boto3.client(
    's3',
    config=boto3.session.Config(
        s3={'use_accelerate_endpoint': True}
    )
)
```

### 6. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Memory ‡πÅ‡∏•‡∏∞ Performance

#### ‚ùå Out of Memory (RAM)
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: `MemoryError` ‡∏´‡∏£‡∏∑‡∏≠ system ‡∏Ñ‡πâ‡∏≤‡∏á
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏•‡∏î num_workers
config['Train']['loader']['num_workers'] = 2

# ‡∏•‡∏î batch size
config['Train']['loader']['batch_size_per_card'] = 4

# ‡πÉ‡∏ä‡πâ data prefetch
config['Train']['loader']['use_shared_memory'] = False

# ‡πÄ‡∏û‡∏¥‡πà‡∏° memory monitoring
import psutil
import os

def monitor_memory():
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    print(f"RSS: {memory_info.rss / 1024 / 1024:.2f} MB")
    print(f"VMS: {memory_info.vms / 1024 / 1024:.2f} MB")
```

#### ‚ùå Training ‡∏ä‡πâ‡∏≤
**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: Training ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥
**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
# ‡∏õ‡∏£‡∏±‡∏ö IO optimization
config['Train']['loader']['num_workers'] = min(8, os.cpu_count())
config['Train']['loader']['prefetch_factor'] = 2

# ‡∏•‡∏î image augmentation
# ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ augmentation ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

# ‡πÄ‡∏û‡∏¥‡πà‡∏° mixed precision training (‡∏ñ‡πâ‡∏≤ GPU ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
config['Global']['use_amp'] = True
config['Global']['scale_loss'] = 128.0
```

## üîß ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ Debug

### 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Configuration
```python
def validate_config(config_path):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á config file
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    required_keys = [
        'Global', 'Architecture', 'Loss', 'Optimizer', 
        'PostProcess', 'Metric', 'Train', 'Eval'
    ]
    
    missing_keys = []
    for key in required_keys:
        if key not in config:
            missing_keys.append(key)
    
    if missing_keys:
        print(f"Missing required keys: {missing_keys}")
        return False
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö paths
    train_data_dir = config['Train']['dataset']['data_dir']
    if not os.path.exists(train_data_dir):
        print(f"Train data directory not found: {train_data_dir}")
        return False
    
    print("Configuration validation passed!")
    return True
```

### 2. ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Data Loading
```python
def test_data_loading(config_path):
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    import paddle
    from ppocr.data import build_dataloader
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    try:
        train_dataloader = build_dataloader(config, 'Train', device='gpu')
        
        print("Testing data loading...")
        for i, batch in enumerate(train_dataloader):
            if i >= 3:  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 3 batch ‡πÅ‡∏£‡∏Å
                break
            
            print(f"Batch {i}: {batch['image'].shape}")
            
        print("Data loading test passed!")
        return True
        
    except Exception as e:
        print(f"Data loading test failed: {e}")
        return False
```

### 3. ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Model
```python
def test_model_creation(config_path):
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á model
    """
    import paddle
    from ppocr.modeling.architectures import build_model
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    try:
        model = build_model(config['Architecture'])
        model.eval()
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö forward pass
        if config['Architecture']['model_type'] == 'det':
            dummy_input = paddle.randn([1, 3, 640, 640])
        else:
            dummy_input = paddle.randn([1, 3, 32, 320])
        
        output = model(dummy_input)
        print(f"Model test passed! Output shape: {output.shape}")
        return True
        
    except Exception as e:
        print(f"Model test failed: {e}")
        return False
```

## üìä Performance Monitoring

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° Training Progress
```python
import time
import psutil
import paddle

class TrainingMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.step_times = []
        
    def log_step(self, step, loss, lr):
        current_time = time.time()
        step_time = current_time - self.start_time
        self.step_times.append(step_time)
        
        # Memory usage
        memory_usage = psutil.virtual_memory().percent
        gpu_memory = paddle.device.cuda.memory_reserved() / 1024**3
        
        # Estimated time remaining
        if len(self.step_times) > 10:
            avg_step_time = sum(self.step_times[-10:]) / 10
            steps_remaining = 1000 - step  # ‡∏™‡∏°‡∏°‡∏ï‡∏¥ total 1000 steps
            eta = avg_step_time * steps_remaining
            
            print(f"Step: {step}, Loss: {loss:.4f}, LR: {lr:.6f}")
            print(f"Memory: {memory_usage:.1f}%, GPU: {gpu_memory:.1f}GB")
            print(f"ETA: {eta/3600:.2f} hours")
```

---

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô `problem-log.md` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï
