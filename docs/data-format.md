# ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition (Data Format Guide)

## üìã ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå Annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition

### ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á PaddleOCR Recognition
‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå text (.txt) ‡πÇ‡∏î‡∏¢‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
```
image_path\ttext_content
```

**‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡∏±‡∏î (bounding box coordinates) ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Detection**

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition
```
images/word_001.jpg	‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ
images/word_002.jpg	‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö
images/word_003.jpg	PaddleOCR
images/word_004.jpg	1234567890
images/word_005.jpg	Hello World
images/word_006.jpg	Ê∑±Â∫¶Â≠¶‰π†
images/word_007.jpg	Machine Learning
```

## üñºÔ∏è ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition

### ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (Cropped Text Images)
- **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö**: JPG, JPEG, PNG, TIFF, BMP
- **‡∏Ç‡∏ô‡∏≤‡∏î**: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á 100-400 pixels, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á 32-64 pixels
- **Aspect Ratio**: ‡πÇ‡∏î‡∏¢‡∏õ‡∏Å‡∏ï‡∏¥ 3:1 ‡∏ñ‡∏∂‡∏á 10:1 (‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏™‡∏π‡∏á)
- **‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤**: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î (cropped) ‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß
- **Color Space**: RGB ‡∏´‡∏£‡∏∑‡∏≠ Grayscale

### ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Recognition
```python
import cv2
import numpy as np

def preprocess_recognition_image(image_path, target_height=32):
    """
    ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition
    """
    image = cv2.imread(image_path)
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö target_height
    h, w = image.shape[:2]
    aspect_ratio = w / h
    new_width = int(target_height * aspect_ratio)
    
    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    max_width = 320
    if new_width > max_width:
        new_width = max_width
    
    image = cv2.resize(image, (new_width, target_height))
    
    return image
```

## üìä ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition

### ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition
```
image_path	text_content
```

### ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition
- **Image Path**: ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß (cropped text image)
- **Text Content**: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (ground truth text)
- **Separator**: Tab character (\t) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- **Encoding**: UTF-8 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤
```python
# ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
cropped_images/thai_001.jpg	‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
cropped_images/thai_002.jpg	‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö

# ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
cropped_images/eng_001.jpg	Hello World
cropped_images/eng_002.jpg	PaddleOCR

# ‡∏†‡∏≤‡∏©‡∏≤‡∏à‡∏µ‡∏ô
cropped_images/chi_001.jpg	Ê∑±Â∫¶Â≠¶‰π†
cropped_images/chi_002.jpg	‰∫∫Â∑•Êô∫ËÉΩ

# ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
cropped_images/num_001.jpg	1234567890
cropped_images/num_002.jpg	2023-08-21
```

## üîß ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á Annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition

### 1. ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å Detection ‡πÄ‡∏õ‡πá‡∏ô Recognition
```python
def convert_detection_to_recognition(detection_annotation_file, images_dir, output_dir):
    """
    ‡πÅ‡∏õ‡∏•‡∏á Detection annotation ‡πÄ‡∏õ‡πá‡∏ô Recognition annotation
    ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏° bounding box ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á annotation ‡πÉ‡∏´‡∏°‡πà
    """
    import json
    import cv2
    import os
    
    recognition_annotations = []
    os.makedirs(output_dir, exist_ok=True)
    
    with open(detection_annotation_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f):
            line = line.strip()
            if not line:
                continue
            
            try:
                image_path, annotation_json = line.split('\t')
                annotations = json.loads(annotation_json)
                
                # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
                full_image_path = os.path.join(images_dir, image_path)
                image = cv2.imread(full_image_path)
                
                if image is None:
                    continue
                
                for idx, ann in enumerate(annotations):
                    text = ann['transcription']
                    points = ann['points']
                    
                    # ‡∏ï‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏° bounding box
                    cropped = crop_text_region(image, points)
                    
                    if cropped is not None:
                        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î
                        crop_filename = f"crop_{line_num:06d}_{idx:03d}.jpg"
                        crop_path = os.path.join(output_dir, crop_filename)
                        cv2.imwrite(crop_path, cropped)
                        
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Recognition annotation
                        recognition_annotations.append(f"{crop_filename}\t{text}")
                        
            except Exception as e:
                print(f"Error processing line {line_num}: {e}")
                continue
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå Recognition annotation
    output_annotation_file = os.path.join(output_dir, 'recognition_annotations.txt')
    with open(output_annotation_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(recognition_annotations))
    
    return output_annotation_file

def crop_text_region(image, points):
    """
    ‡∏ï‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    """
    import cv2
    import numpy as np
    
    points = np.array(points, dtype=np.int32)
    x, y, w, h = cv2.boundingRect(points)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° padding
    padding = 5
    x = max(0, x - padding)
    y = max(0, y - padding)
    w = min(image.shape[1] - x, w + 2 * padding)
    h = min(image.shape[0] - y, h + 2 * padding)
    
    # ‡∏ï‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    cropped = image[y:y+h, x:x+w]
    
    return cropped if cropped.size > 0 else None
```

## ‚úÖ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Annotation
```python
def validate_annotation_quality(annotation_file):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå annotation
    """
    issues = []
    
    with open(annotation_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            
            try:
                parts = line.split('\t')
                if len(parts) != 2:
                    issues.append(f"Line {line_num}: Invalid format")
                    continue
                
                image_path, annotation_json = parts
                annotations = json.loads(annotation_json)
                
                for i, ann in enumerate(annotations):
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö required fields
                    if 'transcription' not in ann:
                        issues.append(f"Line {line_num}, annotation {i}: Missing transcription")
                    
                    if 'points' not in ann:
                        issues.append(f"Line {line_num}, annotation {i}: Missing points")
                        continue
                    
                    points = ann['points']
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏∏‡∏î
                    if len(points) != 4:
                        issues.append(f"Line {line_num}, annotation {i}: Must have 4 points")
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏∏‡∏î
                    for j, point in enumerate(points):
                        if not isinstance(point, list) or len(point) != 2:
                            issues.append(f"Line {line_num}, annotation {i}, point {j}: Invalid point format")
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏à‡∏∏‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
                    if len(points) == 4:
                        area = calculate_polygon_area(points)
                        if area < 10:  # ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                            issues.append(f"Line {line_num}, annotation {i}: Text area too small")
            
            except json.JSONDecodeError:
                issues.append(f"Line {line_num}: Invalid JSON")
            except Exception as e:
                issues.append(f"Line {line_num}: {str(e)}")
    
    return issues

def calculate_polygon_area(points):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°
    """
    x = [p[0] for p in points]
    y = [p[1] for p in points]
    return 0.5 * abs(sum(x[i]*y[i+1] - x[i+1]*y[i] for i in range(-1, len(x)-1)))
```

### 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
```python
def analyze_dataset_distribution(annotation_file):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á dataset
    """
    text_lengths = []
    text_counts_per_image = []
    character_frequency = {}
    
    with open(annotation_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            
            try:
                parts = line.split('\t')
                annotations = json.loads(parts[1])
                
                image_text_count = len(annotations)
                text_counts_per_image.append(image_text_count)
                
                for ann in annotations:
                    text = ann['transcription']
                    text_lengths.append(len(text))
                    
                    # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
                    for char in text:
                        character_frequency[char] = character_frequency.get(char, 0) + 1
                        
            except:
                continue
    
    # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    stats = {
        'total_images': len(text_counts_per_image),
        'total_text_instances': sum(text_counts_per_image),
        'avg_text_per_image': np.mean(text_counts_per_image),
        'avg_text_length': np.mean(text_lengths),
        'unique_characters': len(character_frequency),
        'most_common_chars': sorted(character_frequency.items(), key=lambda x: x[1], reverse=True)[:20]
    }
    
    return stats
```

## üìù ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Recognition

### ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text Recognition
```
cropped_image_path\ttext_content
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Recognition Annotation
```
rec_images/word_001.jpg	‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ
rec_images/word_002.jpg	‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö
rec_images/word_003.jpg	1234567890
rec_images/word_004.jpg	ABC-123
```

### ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Recognition ‡∏à‡∏≤‡∏Å Detection Data
```python
def create_recognition_dataset(detection_annotation_file, image_dir, output_dir):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö recognition ‡∏à‡∏≤‡∏Å detection annotations
    """
    import cv2
    import os
    
    os.makedirs(output_dir, exist_ok=True)
    rec_annotations = []
    
    with open(detection_annotation_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f):
            line = line.strip()
            if not line:
                continue
            
            try:
                image_path, annotation_json = line.split('\t')
                annotations = json.loads(annotation_json)
                
                # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                full_image_path = os.path.join(image_dir, image_path)
                image = cv2.imread(full_image_path)
                
                if image is None:
                    continue
                
                for ann_idx, ann in enumerate(annotations):
                    text = ann['transcription']
                    points = ann['points']
                    
                    # ‡∏ï‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏° bounding box
                    cropped = crop_text_region(image, points)
                    
                    if cropped is not None:
                        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß
                        crop_filename = f"crop_{line_num:06d}_{ann_idx:03d}.jpg"
                        crop_path = os.path.join(output_dir, crop_filename)
                        cv2.imwrite(crop_path, cropped)
                        
                        # ‡πÄ‡∏û‡∏¥‡πà‡∏° annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö recognition
                        rec_annotations.append(f"{crop_filename}\t{text}")
                        
            except Exception as e:
                print(f"Error processing line {line_num}: {e}")
                continue
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå annotation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö recognition
    rec_annotation_file = os.path.join(output_dir, 'rec_annotations.txt')
    with open(rec_annotation_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(rec_annotations))
    
    return rec_annotation_file

def crop_text_region(image, points):
    """
    ‡∏ï‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    """
    import cv2
    import numpy as np
    
    # ‡∏´‡∏≤ bounding rectangle
    points = np.array(points, dtype=np.int32)
    x, y, w, h = cv2.boundingRect(points)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° padding
    padding = 5
    x = max(0, x - padding)
    y = max(0, y - padding)
    w = min(image.shape[1] - x, w + 2 * padding)
    h = min(image.shape[0] - y, h + 2 * padding)
    
    # ‡∏ï‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    cropped = image[y:y+h, x:x+w]
    
    return cropped if cropped.size > 0 else None
```

---

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PaddleOCR ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡πà‡∏á‡∏Ñ‡∏£‡∏±‡∏î ‡∏´‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
